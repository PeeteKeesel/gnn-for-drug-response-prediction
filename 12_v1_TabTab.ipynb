{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pickle\n",
    "import torch\n",
    "import copy\n",
    "import torch.nn          as nn\n",
    "import numpy             as np\n",
    "import pandas            as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn           as sns\n",
    "\n",
    "from tqdm                   import tqdm \n",
    "from typing                 import List\n",
    "from tabulate               import tabulate\n",
    "from torch.utils.data       import Dataset, DataLoader\n",
    "from torch_geometric.loader import DataLoader as PyG_Dataloader\n",
    "\n",
    "from config import PATH_SUMMARY_DATASETS\n",
    "\n",
    "torch.manual_seed(42)\n",
    "sns.set_theme(style=\"white\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Experiments on the `TabTab` approach\n",
    "\n",
    "In this notebook we are going to expirment the approach of \n",
    "- having the cell-line branch using tabular input (`Tab`)\n",
    "- having the drug branch using tabular input (`Tab`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "WITHOUT_MISSING_FOLDER = '/without_missing/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Root datasets\n",
    "\n",
    "- The final datasets have been created in `15_summary_datasets.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the cell-line gene graphs.\n",
    "with open(f'{PATH_SUMMARY_DATASETS}{WITHOUT_MISSING_FOLDER}cell_line_gene_matrix.pkl', 'rb') as f:\n",
    "    cl_gene_mat = pickle.load(f)\n",
    "\n",
    "# Reading the drug SMILES fingerprint table.\n",
    "with open(f'{PATH_SUMMARY_DATASETS}drug_smiles_fingerprints_matrix.pkl', 'rb') as f:\n",
    "    drug_mat = pickle.load(f)\n",
    "\n",
    "# Reading the drug response matrix.\n",
    "with open(f'{PATH_SUMMARY_DATASETS}{WITHOUT_MISSING_FOLDER}drug_response_matrix__gdsc2.pkl', 'rb') as f: \n",
    "    drm = pickle.load(f)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell-line gene matrix\n",
      "=====================\n",
      "(732, 3432)\n",
      "unique cell-lines: 732\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FBXL12_gexpr</th>\n",
       "      <th>PIN1_gexpr</th>\n",
       "      <th>PAK4_gexpr</th>\n",
       "      <th>GNA15_gexpr</th>\n",
       "      <th>ARPP19_gexpr</th>\n",
       "      <th>EAPP_gexpr</th>\n",
       "      <th>MOK_gexpr</th>\n",
       "      <th>MTHFD2_gexpr</th>\n",
       "      <th>TIPARP_gexpr</th>\n",
       "      <th>CASP3_gexpr</th>\n",
       "      <th>...</th>\n",
       "      <th>PDHX_mut</th>\n",
       "      <th>DFFB_mut</th>\n",
       "      <th>FOSL1_mut</th>\n",
       "      <th>ETS1_mut</th>\n",
       "      <th>EBNA1BP2_mut</th>\n",
       "      <th>MYL9_mut</th>\n",
       "      <th>MLLT11_mut</th>\n",
       "      <th>PFKL_mut</th>\n",
       "      <th>FGFR4_mut</th>\n",
       "      <th>SDHB_mut</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CELL_LINE_NAME</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22RV1</th>\n",
       "      <td>7.023759</td>\n",
       "      <td>6.067534</td>\n",
       "      <td>4.318750</td>\n",
       "      <td>3.261427</td>\n",
       "      <td>6.297582</td>\n",
       "      <td>8.313991</td>\n",
       "      <td>5.514912</td>\n",
       "      <td>10.594112</td>\n",
       "      <td>5.222366</td>\n",
       "      <td>6.635925</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23132-87</th>\n",
       "      <td>6.714387</td>\n",
       "      <td>5.695096</td>\n",
       "      <td>4.536146</td>\n",
       "      <td>3.295886</td>\n",
       "      <td>7.021037</td>\n",
       "      <td>8.500080</td>\n",
       "      <td>4.862145</td>\n",
       "      <td>10.609245</td>\n",
       "      <td>6.528668</td>\n",
       "      <td>7.238143</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42-MG-BA</th>\n",
       "      <td>7.752402</td>\n",
       "      <td>5.475753</td>\n",
       "      <td>4.033714</td>\n",
       "      <td>3.176525</td>\n",
       "      <td>7.279671</td>\n",
       "      <td>8.013367</td>\n",
       "      <td>4.957332</td>\n",
       "      <td>11.266705</td>\n",
       "      <td>7.445954</td>\n",
       "      <td>6.312424</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 3432 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                FBXL12_gexpr  PIN1_gexpr  PAK4_gexpr  GNA15_gexpr  \\\n",
       "CELL_LINE_NAME                                                      \n",
       "22RV1               7.023759    6.067534    4.318750     3.261427   \n",
       "23132-87            6.714387    5.695096    4.536146     3.295886   \n",
       "42-MG-BA            7.752402    5.475753    4.033714     3.176525   \n",
       "\n",
       "                ARPP19_gexpr  EAPP_gexpr  MOK_gexpr  MTHFD2_gexpr  \\\n",
       "CELL_LINE_NAME                                                      \n",
       "22RV1               6.297582    8.313991   5.514912     10.594112   \n",
       "23132-87            7.021037    8.500080   4.862145     10.609245   \n",
       "42-MG-BA            7.279671    8.013367   4.957332     11.266705   \n",
       "\n",
       "                TIPARP_gexpr  CASP3_gexpr  ...  PDHX_mut  DFFB_mut  FOSL1_mut  \\\n",
       "CELL_LINE_NAME                             ...                                  \n",
       "22RV1               5.222366     6.635925  ...       1.0       0.0        0.0   \n",
       "23132-87            6.528668     7.238143  ...       0.0       0.0        0.0   \n",
       "42-MG-BA            7.445954     6.312424  ...       0.0       0.0        0.0   \n",
       "\n",
       "                ETS1_mut  EBNA1BP2_mut  MYL9_mut  MLLT11_mut  PFKL_mut  \\\n",
       "CELL_LINE_NAME                                                           \n",
       "22RV1                0.0           0.0       0.0         1.0       0.0   \n",
       "23132-87             0.0           0.0       0.0         0.0       0.0   \n",
       "42-MG-BA             0.0           0.0       0.0         0.0       0.0   \n",
       "\n",
       "                FGFR4_mut  SDHB_mut  \n",
       "CELL_LINE_NAME                       \n",
       "22RV1                 1.0       0.0  \n",
       "23132-87              0.0       0.0  \n",
       "42-MG-BA              0.0       0.0  \n",
       "\n",
       "[3 rows x 3432 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Cell-line gene matrix\\n{21*'='}\")\n",
    "assert len([col for col in cl_gene_mat.columns[1:] if '_gexpr' in col]) == \\\n",
    "    len([col for col in cl_gene_mat.columns[1:] if '_cnvg' in col]) == \\\n",
    "    len([col for col in cl_gene_mat.columns[1:] if '_cnvp' in col]) == \\\n",
    "    len([col for col in cl_gene_mat.columns[1:] if '_mut' in col])\n",
    "cl_gene_mat.set_index('CELL_LINE_NAME', inplace=True)    \n",
    "print(cl_gene_mat.shape)\n",
    "print(f\"unique cell-lines: {len(cl_gene_mat.index.unique())}\")\n",
    "cl_gene_mat.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drug SMILES fingerprint matrix\n",
      "==============================\n",
      "(152, 256)\n",
      "unique drugs: 152\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>246</th>\n",
       "      <th>247</th>\n",
       "      <th>248</th>\n",
       "      <th>249</th>\n",
       "      <th>250</th>\n",
       "      <th>251</th>\n",
       "      <th>252</th>\n",
       "      <th>253</th>\n",
       "      <th>254</th>\n",
       "      <th>255</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DRUG_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1073</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1910</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1913</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 256 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0    1    2    3    4    5    6    7    8    9    ...  246  247  248  \\\n",
       "DRUG_ID                                                    ...                  \n",
       "1073       0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "1910       1    1    0    0    0    0    0    0    0    0  ...    1    0    0   \n",
       "1913       0    1    1    0    1    0    0    0    0    0  ...    0    0    0   \n",
       "\n",
       "         249  250  251  252  253  254  255  \n",
       "DRUG_ID                                     \n",
       "1073       0    0    0    0    0    0    1  \n",
       "1910       0    0    1    0    0    0    1  \n",
       "1913       0    1    1    0    0    0    0  \n",
       "\n",
       "[3 rows x 256 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Drug SMILES fingerprint matrix\\n{30*'='}\")\n",
    "drug_mat.set_index('DRUG_ID', inplace=True)\n",
    "print(drug_mat.shape)\n",
    "print(f\"unique drugs: {len(drug_mat.index.unique())}\")\n",
    "drug_mat.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drug response matrix\n",
      "====================\n",
      "(91991, 5)\n",
      "unique cell-lines: 732\n",
      "unique drugs     : 152\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CELL_LINE_NAME</th>\n",
       "      <th>DRUG_ID</th>\n",
       "      <th>DRUG_NAME</th>\n",
       "      <th>DATASET</th>\n",
       "      <th>LN_IC50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3441054</th>\n",
       "      <td>22RV1</td>\n",
       "      <td>1003</td>\n",
       "      <td>Camptothecin</td>\n",
       "      <td>GDSC2</td>\n",
       "      <td>-3.142631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3459252</th>\n",
       "      <td>22RV1</td>\n",
       "      <td>1004</td>\n",
       "      <td>Vinblastine</td>\n",
       "      <td>GDSC2</td>\n",
       "      <td>-4.459259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3508920</th>\n",
       "      <td>22RV1</td>\n",
       "      <td>1006</td>\n",
       "      <td>Cytarabine</td>\n",
       "      <td>GDSC2</td>\n",
       "      <td>3.826935</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        CELL_LINE_NAME  DRUG_ID     DRUG_NAME DATASET   LN_IC50\n",
       "3441054          22RV1     1003  Camptothecin   GDSC2 -3.142631\n",
       "3459252          22RV1     1004   Vinblastine   GDSC2 -4.459259\n",
       "3508920          22RV1     1006    Cytarabine   GDSC2  3.826935"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Drug response matrix\\n{20*'='}\")\n",
    "print(drm.shape)\n",
    "print(f\"unique cell-lines: {len(drm.CELL_LINE_NAME.unique())}\")\n",
    "print(f\"unique drugs     : {len(drm.DRUG_ID.unique())}\")\n",
    "drm.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create `PyTorch` dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Dataset as PyGDataset\n",
    "\n",
    "class TabTabDataset(PyGDataset):\n",
    "    def __init__(self, cl_mat, drug_mat, drm):\n",
    "        super().__init__()\n",
    "        self.cl_mat = cl_mat\n",
    "        self.drug_mat = drug_mat\n",
    "\n",
    "        drm.reset_index(drop=True, inplace=True)\n",
    "        self.cls = drm['CELL_LINE_NAME']\n",
    "        self.drug_ids = drm['DRUG_ID']\n",
    "        self.drug_names = drm['DRUG_NAME']\n",
    "        self.ic50s = drm['LN_IC50']\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ic50s)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        \"\"\"\n",
    "        Returns a tuple of cell-line-gene features, drug smiles fingerprints \n",
    "        and the corresponding ln(IC50) values for a given index.\n",
    "\n",
    "        Args:\n",
    "            idx (`int`): Index to specify the row in the drug response matrix.  \n",
    "        Returns\n",
    "            `Tuple[np.ndarray, np.ndarray, np.float64]]`: Tuple of cell-line \n",
    "                gene feature values, drug SMILES fingerprints and the \n",
    "                corresponding ln(IC50) target values.\n",
    "        \"\"\"\n",
    "        return (self.cl_mat.loc[self.cls.iloc[idx]], \n",
    "                self.drug_mat.loc[self.drug_ids.iloc[idx]],\n",
    "                self.ic50s.iloc[idx])\n",
    "\n",
    "    def print_summary(self):\n",
    "        print(f\"TabTabDataset Summary\")\n",
    "        print(21*'=')\n",
    "        print(f\"# observations :\", len(self.ic50s))\n",
    "        print(f\"# cell-lines   :\", len(np.unique(self.cls)))\n",
    "        print(f\"# drugs        :\", len(np.unique(self.drug_names)))\n",
    "        print(f\"# genes        :\", len([col for col in self.cl_mat.columns[1:] if '_cnvg' in col]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TabTabDataset Summary\n",
      "=====================\n",
      "# observations : 91991\n",
      "# cell-lines   : 732\n",
      "# drugs        : 152\n",
      "# genes        : 858\n"
     ]
    }
   ],
   "source": [
    "tab_tab_dataset = TabTabDataset(cl_mat=cl_gene_mat, drug_mat=drug_mat, drm=drm)\n",
    "tab_tab_dataset.print_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self, batch_size, lr, train_ratio, val_ratio, num_epochs):\n",
    "        self.BATCH_SIZE = batch_size\n",
    "        self.LR = lr\n",
    "        self.TRAIN_RATIO = train_ratio\n",
    "        self.TEST_VAL_RATIO = 1-self.TRAIN_RATIO\n",
    "        self.VAL_RATIO = val_ratio\n",
    "        self.NUM_EPOCHS = num_epochs\n",
    "        self.RANDOM_SEED = 12345      \n",
    "\n",
    "args = Args(batch_size=1_000, \n",
    "            lr=0.0001, \n",
    "            train_ratio=0.8, \n",
    "            val_ratio=0.5, \n",
    "            num_epochs=300)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create `DataLoader` datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CELL_LINE_NAME    False\n",
      "DRUG_ID           False\n",
      "DRUG_NAME         False\n",
      "DATASET           False\n",
      "LN_IC50           False\n",
      "dtype: bool\n",
      "FBXL12_gexpr    False\n",
      "PIN1_gexpr      False\n",
      "PAK4_gexpr      False\n",
      "GNA15_gexpr     False\n",
      "ARPP19_gexpr    False\n",
      "                ...  \n",
      "MYL9_mut        False\n",
      "MLLT11_mut      False\n",
      "PFKL_mut        False\n",
      "FGFR4_mut       False\n",
      "SDHB_mut        False\n",
      "Length: 3432, dtype: bool\n",
      "0      False\n",
      "1      False\n",
      "2      False\n",
      "3      False\n",
      "4      False\n",
      "       ...  \n",
      "251    False\n",
      "252    False\n",
      "253    False\n",
      "254    False\n",
      "255    False\n",
      "Length: 256, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "print(drm.isna().any())\n",
    "print(cl_gene_mat.isna().any())\n",
    "print(drug_mat.isna().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FBXL12_gexpr    0\n",
       "PIN1_gexpr      0\n",
       "PAK4_gexpr      0\n",
       "GNA15_gexpr     0\n",
       "ARPP19_gexpr    0\n",
       "               ..\n",
       "PFKL_gexpr      0\n",
       "FGFR4_gexpr     0\n",
       "SDHB_gexpr      0\n",
       "FBXL12_cnvg     0\n",
       "PIN1_cnvg       0\n",
       "Length: 860, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl_gene_mat.isna().sum().head(860)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set.shape: (73592, 5)\n",
      "test_set.shape: (9199, 5)\n",
      "val_set.shape: (9200, 5)\n",
      "\n",
      "train_dataset\n",
      "TabTabDataset Summary\n",
      "=====================\n",
      "# observations : 73592\n",
      "# cell-lines   : 732\n",
      "# drugs        : 152\n",
      "# genes        : 858\n",
      "\n",
      "test_dataset\n",
      "TabTabDataset Summary\n",
      "=====================\n",
      "# observations : 9199\n",
      "# cell-lines   : 732\n",
      "# drugs        : 152\n",
      "# genes        : 858\n",
      "\n",
      "val_dataset\n",
      "TabTabDataset Summary\n",
      "=====================\n",
      "# observations : 9200\n",
      "# cell-lines   : 732\n",
      "# drugs        : 152\n",
      "# genes        : 858\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def _collate_tab_tab(samples):\n",
    "    cls, drugs, ic50s = map(list, zip(*samples))\n",
    "    cls = [torch.tensor(cl, dtype=torch.float64) for cl in cls]\n",
    "    drugs = [torch.tensor(drug, dtype=torch.float64) for drug in drugs]\n",
    "    # print(\"\\nCELL-LINES: \", cls[0])\n",
    "    # print(\"\\nDRUG:\", drugs[0])\n",
    "    # print(\"\\nIC50: \", ic50s[0])\n",
    "    \n",
    "    return torch.stack(cls, 0), torch.stack(drugs, 0), torch.tensor(ic50s)\n",
    "\n",
    "def create_datasets(drm, cl_mat, drug_mat):\n",
    "    train_set, test_val_set = train_test_split(drm, test_size=args.TEST_VAL_RATIO, random_state=args.RANDOM_SEED, stratify=drm['CELL_LINE_NAME'])\n",
    "    test_set, val_set = train_test_split(test_val_set, test_size=args.VAL_RATIO, random_state=args.RANDOM_SEED, stratify=test_val_set['CELL_LINE_NAME'])\n",
    "\n",
    "    print(\"train_set.shape:\", train_set.shape)\n",
    "    print(\"test_set.shape:\", test_set.shape)\n",
    "    print(\"val_set.shape:\", val_set.shape)\n",
    "\n",
    "    train_dataset = TabTabDataset(cl_mat=cl_mat, drug_mat=drug_mat, drm=train_set)\n",
    "    test_dataset = TabTabDataset(cl_mat=cl_mat, drug_mat=drug_mat, drm=test_set)\n",
    "    val_dataset = TabTabDataset(cl_mat=cl_mat, drug_mat=drug_mat, drm=val_set)\n",
    "\n",
    "    print(\"\\ntrain_dataset\"); train_dataset.print_summary()\n",
    "    print(\"\\ntest_dataset\"); test_dataset.print_summary()\n",
    "    print(\"\\nval_dataset\"); val_dataset.print_summary()\n",
    "\n",
    "    train_loader = DataLoader(dataset=train_dataset, batch_size=args.BATCH_SIZE, shuffle=True, collate_fn=_collate_tab_tab)\n",
    "    test_loader = DataLoader(dataset=test_dataset, batch_size=args.BATCH_SIZE, shuffle=True, collate_fn=_collate_tab_tab)\n",
    "    val_loader = DataLoader(dataset=val_dataset, batch_size=args.BATCH_SIZE, shuffle=True, collate_fn=_collate_tab_tab)\n",
    "\n",
    "    return train_loader, test_loader, val_loader\n",
    "\n",
    "train_loader, test_loader, val_loader = create_datasets(drm, cl_gene_mat, drug_mat)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of batches per dataset:\n",
      "  train : 74\n",
      "  test  : 10\n",
      "  val   : 10\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of batches per dataset:\")\n",
    "print(f\"  train : {len(train_loader)}\")\n",
    "print(f\"  test  : {len(test_loader)}\")\n",
    "print(f\"  val   : {len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(FBXL12_gexpr    7.023759\n",
       " PIN1_gexpr      6.067534\n",
       " PAK4_gexpr      4.318750\n",
       " GNA15_gexpr     3.261427\n",
       " ARPP19_gexpr    6.297582\n",
       "                   ...   \n",
       " MYL9_mut        0.000000\n",
       " MLLT11_mut      1.000000\n",
       " PFKL_mut        0.000000\n",
       " FGFR4_mut       1.000000\n",
       " SDHB_mut        0.000000\n",
       " Name: 22RV1, Length: 3432, dtype: float64,\n",
       " 0      1\n",
       " 1      0\n",
       " 2      0\n",
       " 3      0\n",
       " 4      0\n",
       "       ..\n",
       " 251    1\n",
       " 252    0\n",
       " 253    0\n",
       " 254    0\n",
       " 255    0\n",
       " Name: 1004, Length: 256, dtype: int64,\n",
       " -4.459259)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tab_tab_dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1:\n",
      "=======\n",
      "torch.Size([1000, 3432])\n",
      "torch.Size([1000, 256])\n",
      "torch.Size([1000])\n",
      "Step 2:\n",
      "=======\n",
      "torch.Size([1000, 3432])\n",
      "torch.Size([1000, 256])\n",
      "torch.Size([1000])\n",
      "Step 3:\n",
      "=======\n",
      "torch.Size([1000, 3432])\n",
      "torch.Size([1000, 256])\n",
      "torch.Size([1000])\n",
      "... step 10\n",
      "... step 20\n",
      "... step 30\n",
      "... step 40\n",
      "... step 50\n",
      "... step 60\n",
      "... step 70\n",
      "Step 74:\n",
      "=======\n",
      "torch.Size([592, 3432])\n",
      "torch.Size([592, 256])\n",
      "torch.Size([592])\n"
     ]
    }
   ],
   "source": [
    "for step, data in enumerate(train_loader):\n",
    "    if (step > 2) & (step < len(train_loader)-1):\n",
    "        if step % 10 == 0: \n",
    "            print(\"... step\", step) \n",
    "        continue\n",
    "    else:\n",
    "        cl_mat, drug_mat, ic50s = data\n",
    "        print(f'Step {step + 1}:')\n",
    "        print(f'=======')    \n",
    "        print(cl_mat.shape)\n",
    "        print(drug_mat.shape)\n",
    "        print(ic50s.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from time import sleep\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "\n",
    "class BuildModel:\n",
    "    def __init__(self, model, criterion, optimizer, num_epochs, \n",
    "        train_loader, test_loader, val_loader, device):\n",
    "        self.train_losses = []\n",
    "        self.test_losses = []\n",
    "        self.val_losses = []\n",
    "        self.train_loader = train_loader \n",
    "        self.test_loader = test_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.num_epochs = num_epochs\n",
    "        self.model = model \n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer \n",
    "        self.device = device\n",
    "\n",
    "    def train(self, loader): \n",
    "        train_epoch_losses, val_epoch_losses = [], []\n",
    "        all_batch_losses = [] # TODO: this is just for monitoring\n",
    "        n_batches = len(loader)\n",
    "        for epoch in range(self.num_epochs): \n",
    "            self.model.train()\n",
    "            # print(\"=====Epoch \", epoch, \" | Training...\")\n",
    "            batch_losses = []\n",
    "            for data in tqdm(loader, desc='Iter', position=0, leave=True):\n",
    "                sleep(0.01)\n",
    "                cl, dr, ic50 = data\n",
    "                cl, dr, ic50 = cl.to(self.device), dr.to(self.device), ic50.to(self.device)\n",
    "                # print(\"cl: \", cl.shape, cl); print(\"dr: \", dr.shape, dr); print(\"ic50: \", y.shape, y)\n",
    "\n",
    "                self.optimizer.zero_grad()                \n",
    "\n",
    "                preds = self.model(cl.float(), dr.float()).unsqueeze(1) # TODO: unsqueeze can be added to forward\n",
    "                # print(preds.shape)\n",
    "                # print(\"preds:\", preds)\n",
    "                loss = self.criterion(preds, ic50.view(-1,1).float())\n",
    "                batch_losses.append(loss)\n",
    "\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "            # print(batch_losses)\n",
    "            all_batch_losses.append(batch_losses) # TODO: this is just for monitoring\n",
    "            total_epoch_loss = sum(batch_losses)\n",
    "            train_epoch_losses.append(total_epoch_loss / n_batches)\n",
    "\n",
    "            mse, _, _, _, _ = self.validate(val_loader)\n",
    "            val_epoch_losses.append(mse)\n",
    "\n",
    "            if epoch % 25 == 0:\n",
    "                print(\"=====Epoch \", epoch)\n",
    "                print(f\"Train      | MSE: {train_epoch_losses[-1]:2.5f}\")\n",
    "                print(f\"Validation | MSE: {mse:2.5f}\")\n",
    "\n",
    "        return train_epoch_losses, val_epoch_losses\n",
    "\n",
    "    def validate(self, loader):\n",
    "        self.model.eval()\n",
    "        y_true, y_pred = [], []\n",
    "        total_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for data in tqdm(loader, desc='Iter', position=0, leave=True):\n",
    "                sleep(0.01)\n",
    "                cl, dr, ic50 = data\n",
    "\n",
    "                preds = self.model(cl.float(), dr.float()).unsqueeze(1)\n",
    "                ic50 = ic50.to(self.device)\n",
    "                total_loss += self.criterion(preds, ic50.view(-1,1).float())\n",
    "                # total_loss += F.mse_loss(preds, ic50.view(-1, 1).float(), reduction='sum')\n",
    "                y_true.append(ic50.view(-1, 1))\n",
    "                y_pred.append(preds)\n",
    "        \n",
    "        y_true = torch.cat(y_true, dim=0)\n",
    "        y_pred = torch.cat(y_pred, dim=0)\n",
    "        mse = total_loss / len(loader)\n",
    "        rmse = torch.sqrt(mse)\n",
    "        mae = mean_absolute_error(y_true.cpu(), y_pred.cpu())\n",
    "        r2 = r2_score(y_true.cpu(), y_pred.cpu())\n",
    "        pearson_corr_coef, _ = pearsonr(y_true.cpu().numpy().flatten(), \n",
    "                                        y_pred.cpu().numpy().flatten())\n",
    "\n",
    "        return mse, rmse, mae, r2, pearson_corr_coef\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "device: cpu\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "\n",
    "# from TabTab import TabTabModel\n",
    "\n",
    "class TabTabModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TabTabModel, self).__init__()\n",
    "        self.cell_branch = nn.Sequential(\n",
    "            nn.Linear(3432, 516),\n",
    "            nn.BatchNorm1d(516),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.1),\n",
    "            nn.Linear(516, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.1),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU()         \n",
    "        )\n",
    "\n",
    "        self.drug_branch = nn.Sequential(\n",
    "            nn.Linear(256, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.1),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU()          \n",
    "        )\n",
    "\n",
    "        self.fcn = nn.Sequential(\n",
    "            nn.Linear(2*128, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(p=0.1),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(p=0.1),\n",
    "            nn.Linear(64, 1)\n",
    "            # nn.BatchNorm1d(1),\n",
    "            # nn.ReLU()\n",
    "        )     \n",
    "\n",
    "    def forward(self, cell, drug):\n",
    "        cell_emb = self.cell_branch(cell)  # Create cell gene vector embedding.\n",
    "        drug_emb = self.drug_branch(drug)  # Create compound vector embedding.\n",
    "        # print(\"cell_emb: \", cell_emb.shape)\n",
    "        # print(\"drug_emb: \", drug_emb.shape)\n",
    "\n",
    "        concat = torch.cat([cell_emb, drug_emb], 1)\n",
    "        # print(concat.shape)\n",
    "        # print(concat)\n",
    "\n",
    "        # x_dim_batch, y_dim_branch, z_dim_features = concat.shape[0], concat.shape[1], concat.shape[2]\n",
    "        # concat = torch.reshape(concat, (x_dim_batch, y_dim_branch*z_dim_features))\n",
    "        \n",
    "        y_pred = self.fcn(concat)\n",
    "        y_pred = y_pred.reshape(y_pred.shape[0])\n",
    "        return y_pred\n",
    "\n",
    "torch.manual_seed(args.RANDOM_SEED)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"device:\", device)\n",
    "\n",
    "model = TabTabModel().to(device)\n",
    "loss_func = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=args.LR)\n",
    "\n",
    "build_model = BuildModel(model, loss_func, optimizer, args.NUM_EPOCHS, \n",
    "                         train_loader, test_loader, val_loader,\n",
    "                         device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====Epoch  0\n",
      "Train      | MSE: 10.92296\n",
      "Validation | MSE: 7.30963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter: 100%|██████████| 74/74 [01:24<00:00,  1.14s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.05it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:24<00:00,  1.14s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.06it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:25<00:00,  1.15s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:25<00:00,  1.15s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.05it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.03it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.02it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.02it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.04it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.19s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.00it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.02s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:28<00:00,  1.20s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.19s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.03s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:25<00:00,  1.15s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.02s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.03s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:25<00:00,  1.16s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.04s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:28<00:00,  1.19s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.00s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:12<00:00,  1.20s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:24<00:00,  1.14s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.06it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:22<00:00,  1.11s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.08it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:22<00:00,  1.12s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.08it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:22<00:00,  1.12s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.08it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:22<00:00,  1.11s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.08it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:22<00:00,  1.12s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====Epoch  25\n",
      "Train      | MSE: 1.31992\n",
      "Validation | MSE: 1.23547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter: 100%|██████████| 74/74 [01:22<00:00,  1.12s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.08it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:22<00:00,  1.11s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.09it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:22<00:00,  1.11s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.08it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:22<00:00,  1.12s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.06it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:22<00:00,  1.12s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.08it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:23<00:00,  1.12s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.08it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:22<00:00,  1.12s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.09it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:22<00:00,  1.12s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.08it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:22<00:00,  1.11s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.07it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:22<00:00,  1.11s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.08it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:22<00:00,  1.12s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.07it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:22<00:00,  1.11s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.06it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:22<00:00,  1.12s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.07it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:22<00:00,  1.11s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.06it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:22<00:00,  1.12s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.06it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:22<00:00,  1.11s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.06it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:22<00:00,  1.11s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.07it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:22<00:00,  1.12s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.07it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:22<00:00,  1.12s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.06it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:22<00:00,  1.11s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.06it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:22<00:00,  1.11s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.04it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:22<00:00,  1.11s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.06it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:22<00:00,  1.11s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.06it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:22<00:00,  1.11s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.06it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:22<00:00,  1.12s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====Epoch  50\n",
      "Train      | MSE: 1.08509\n",
      "Validation | MSE: 1.00775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter: 100%|██████████| 74/74 [01:23<00:00,  1.12s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.06it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:22<00:00,  1.12s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.07it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:22<00:00,  1.11s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.06it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:22<00:00,  1.11s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.06it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:22<00:00,  1.11s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.06it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:22<00:00,  1.11s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.07it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:23<00:00,  1.12s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.05it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:22<00:00,  1.11s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.05it/s]\n",
      "Iter: 100%|██████████| 74/74 [27:01<00:00, 21.91s/it]   \n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.03s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:28<00:00,  1.19s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.03s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:25<00:00,  1.16s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.19s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.06it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:28<00:00,  1.19s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.00s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:28<00:00,  1.20s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.02it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.04it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.03s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.16s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.05s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:32<00:00,  1.26s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.04it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.02it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.19s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.03s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:28<00:00,  1.19s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.00s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====Epoch  75\n",
      "Train      | MSE: 0.98334\n",
      "Validation | MSE: 0.96934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter: 100%|██████████| 74/74 [01:28<00:00,  1.19s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.00s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:24<00:00,  1.14s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.04it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:23<00:00,  1.13s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.05it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:24<00:00,  1.14s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.02s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:29<00:00,  1.21s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:29<00:00,  1.20s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:29<00:00,  1.20s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.04s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.04it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:24<00:00,  1.15s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.00it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:28<00:00,  1.19s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.19s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.05it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:25<00:00,  1.15s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:28<00:00,  1.19s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.00it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:25<00:00,  1.16s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.08it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.19s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.02it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:25<00:00,  1.15s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.00s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.19s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.02it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:31<00:00,  1.24s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.05it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.19s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====Epoch  100\n",
      "Train      | MSE: 0.92735\n",
      "Validation | MSE: 0.91169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.03it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.03it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.00s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.16s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.03it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.02it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:11<00:00,  1.11s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:24<00:00,  1.14s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.02it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.03it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.02it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.03it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.00s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====Epoch  125\n",
      "Train      | MSE: 0.87510\n",
      "Validation | MSE: 0.92339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.00s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.02it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:25<00:00,  1.16s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:25<00:00,  1.16s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.00it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.02it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.03it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.02s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:28<00:00,  1.20s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.03it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:28<00:00,  1.20s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:11<00:00,  1.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====Epoch  150\n",
      "Train      | MSE: 0.83066\n",
      "Validation | MSE: 0.88861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter: 100%|██████████| 74/74 [01:30<00:00,  1.22s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.00it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.02s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:31<00:00,  1.24s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.05s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:28<00:00,  1.20s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.16s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.00s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:29<00:00,  1.21s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.00s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:28<00:00,  1.20s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.02s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:29<00:00,  1.20s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.02it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:24<00:00,  1.15s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.04it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:24<00:00,  1.14s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.04it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:24<00:00,  1.14s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:24<00:00,  1.14s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.03it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:25<00:00,  1.15s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.03it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:25<00:00,  1.15s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.05it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:22<00:00,  1.11s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.06it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:22<00:00,  1.12s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.04it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:22<00:00,  1.11s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.06it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:23<00:00,  1.13s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.05it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:22<00:00,  1.12s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.06it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:22<00:00,  1.12s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.06it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:28<00:00,  1.20s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.09s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.19s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.07s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:25<00:00,  1.16s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.03s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:30<00:00,  1.22s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====Epoch  175\n",
      "Train      | MSE: 0.79286\n",
      "Validation | MSE: 0.85819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.19s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.03it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.16s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.02s/it]\n",
      "Iter: 100%|██████████| 74/74 [2:01:31<00:00, 98.53s/it]    \n",
      "Iter: 100%|██████████| 10/10 [00:26<00:00,  2.61s/it]\n",
      "Iter:   5%|▌         | 4/74 [00:13<03:56,  3.38s/it]"
     ]
    }
   ],
   "source": [
    "train_losses, val_losses = build_model.train(build_model.train_loader)\n",
    "\n",
    "tr_mse, tr_rmse, tr_mae, tr_r2, tr_r = build_model.validate(build_model.train_loader)\n",
    "val_mse, val_rmse, val_mae, val_r2, val_r = build_model.validate(build_model.val_loader)\n",
    "te_mse, te_rmse, te_mae, te_r2, te_r = build_model.validate(build_model.test_loader)\n",
    "\n",
    "results = tabulate(\n",
    "    [\n",
    "        ['mse', 'rmse', 'mae', 'r2', 'r'],\n",
    "        ['train', tr_mse, tr_rmse, tr_mae, tr_r2, tr_r],\n",
    "        ['validation', val_mse, val_rmse, val_mae, val_r2, val_r],\n",
    "        ['test', te_mse, te_rmse, te_mae, te_r2, te_r]\n",
    "    ], headers='firstrow')\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "n_epochs = 100\n",
    "    mse     rmse       mae        r2         r\n",
    "-------  -------  --------  --------  --------\n",
    "1.34979  1.1618   0.580942  0.814719  0.92687\n",
    "2.09012  1.44572  0.981567  0.709278  0.858571\n",
    "2.14415  1.46429  0.983369  0.709229  0.857674\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 mse      rmse       mae        r2         r\n",
      "----------  --------  --------  --------  --------  --------\n",
      "train       0.450149  0.670932  0.51781   0.938216  0.968843\n",
      "validation  0.811576  0.900875  0.662914  0.889404  0.943088\n",
      "test        0.83026   0.911186  0.669223  0.886715  0.941691\n"
     ]
    }
   ],
   "source": [
    "results = tabulate(\n",
    "    [\n",
    "        ['mse', 'rmse', 'mae', 'r2', 'r'],\n",
    "        ['train', tr_mse, tr_rmse, tr_mae, tr_r2, tr_r],\n",
    "        ['validation', val_mse, val_rmse, val_mae, val_r2, val_r],\n",
    "        ['test', te_mse, te_rmse, te_mae, te_r2, te_r]\n",
    "    ], headers='firstrow')\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA on Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([loss.item() for loss in train_losses], c='C0', label='train');\n",
    "plt.plot([loss.item() for loss in val_losses], c='C1', label='validation');\n",
    "plt.legend();\n",
    "plt.ticklabel_format(style='plain');\n",
    "plt.xlim(0, 2, 1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(build_model.model.state_dict(), '../../datasets/models/TabTab_v1.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 95264\n",
      "-rw-r--r--  1 cwoest  staff   8.1M Sep 28 13:52 Model2CnvGistic__cnv_gistic.pkl\n",
      "-rw-r--r--  1 cwoest  staff   8.1M Sep 28 14:37 Model2CnvGistic__cnv_picnic.pkl\n",
      "-rw-r--r--  1 cwoest  staff   7.8M Nov 11 19:03 TabTab_v1.pkl\n",
      "-rw-r--r--  1 cwoest  staff   7.8M Nov 11 19:04 TabTab_v1.pt\n",
      "-rw-r--r--  1 cwoest  staff   8.1M Sep 28 13:12 model2.pkl\n",
      "-rw-r--r--  1 cwoest  staff   1.3M Aug 24 16:00 simpleNN\n",
      "-rw-r--r--  1 cwoest  staff   1.3M Aug 24 15:58 simpleNN.pkl\n",
      "-rw-r--r--  1 cwoest  staff   4.0M Aug 24 16:03 simpleNN_extensive.pkl\n"
     ]
    }
   ],
   "source": [
    "ls -lh ../../datasets/models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TabTabModel(\n",
       "  (cell_branch): Sequential(\n",
       "    (0): Linear(in_features=3432, out_features=516, bias=True)\n",
       "    (1): BatchNorm1d(516, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.1, inplace=False)\n",
       "    (4): Linear(in_features=516, out_features=256, bias=True)\n",
       "    (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU()\n",
       "    (7): Dropout(p=0.1, inplace=False)\n",
       "    (8): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (9): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): ReLU()\n",
       "  )\n",
       "  (drug_branch): Sequential(\n",
       "    (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.1, inplace=False)\n",
       "    (4): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (5): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU()\n",
       "  )\n",
       "  (fcn): Sequential(\n",
       "    (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ELU(alpha=1.0)\n",
       "    (3): Dropout(p=0.1, inplace=False)\n",
       "    (4): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (5): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ELU(alpha=1.0)\n",
       "    (7): Dropout(p=0.1, inplace=False)\n",
       "    (8): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model = TabTabModel()\n",
    "loaded_model.load_state_dict(torch.load('../../datasets/models/TabTab_v1.pt'))\n",
    "loaded_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.2950, grad_fn=<AddBackward0>)\n",
      "tensor(10.2950, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[tensor(0.9803, grad_fn=<MseLossBackward0>),\n",
       " tensor(2.1797, grad_fn=<MseLossBackward0>),\n",
       " tensor(3.0829, grad_fn=<MseLossBackward0>),\n",
       " tensor(2.1547, grad_fn=<MseLossBackward0>),\n",
       " tensor(1.8975, grad_fn=<MseLossBackward0>)]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outs = []\n",
    "os = 0\n",
    "for i in range(5):\n",
    "\n",
    "    loss = nn.MSELoss()\n",
    "    input = torch.randn(3, 5, requires_grad=True)\n",
    "    target = torch.randn(3, 5)\n",
    "    output = loss(input, target)\n",
    "    outs.append(output)\n",
    "    os += output\n",
    "    output.backward()\n",
    "print(sum(outs))\n",
    "print(os)\n",
    "outs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(13.1052, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c78b81650a0bd32063743affb6953ff71b1a0dba806fbca9e2db842718495748"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('master-thesis-log')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
