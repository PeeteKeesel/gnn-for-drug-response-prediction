{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pickle\n",
    "import torch\n",
    "import copy\n",
    "import torch.nn          as nn\n",
    "import numpy             as np\n",
    "import pandas            as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn           as sns\n",
    "\n",
    "from tqdm                   import tqdm \n",
    "from typing                 import List\n",
    "from tabulate               import tabulate\n",
    "from torch.utils.data       import Dataset, DataLoader\n",
    "from torch_geometric.loader import DataLoader as PyG_Dataloader\n",
    "\n",
    "from config import PATH_SUMMARY_DATASETS\n",
    "\n",
    "torch.manual_seed(42)\n",
    "sns.set_theme(style=\"white\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Experiments on the `TabTab` approach\n",
    "\n",
    "In this notebook we are going to expirment the approach of \n",
    "- having the cell-line branch using tabular input (`Tab`)\n",
    "- having the drug branch using tabular input (`Tab`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "WITHOUT_MISSING_FOLDER = '/without_missing/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Root datasets\n",
    "\n",
    "- The final datasets have been created in `15_summary_datasets.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the cell-line gene graphs.\n",
    "with open(f'{PATH_SUMMARY_DATASETS}{WITHOUT_MISSING_FOLDER}cell_line_gene_matrix.pkl', 'rb') as f:\n",
    "    cl_gene_mat = pickle.load(f)\n",
    "\n",
    "# Reading the drug SMILES fingerprint table.\n",
    "with open(f'{PATH_SUMMARY_DATASETS}drug_smiles_fingerprints_matrix.pkl', 'rb') as f:\n",
    "    drug_mat = pickle.load(f)\n",
    "\n",
    "# Reading the drug response matrix.\n",
    "with open(f'{PATH_SUMMARY_DATASETS}{WITHOUT_MISSING_FOLDER}drug_response_matrix__gdsc2.pkl', 'rb') as f: \n",
    "    drm = pickle.load(f)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell-line gene matrix\n",
      "=====================\n",
      "(732, 3432)\n",
      "unique cell-lines: 732\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FBXL12_gexpr</th>\n",
       "      <th>PIN1_gexpr</th>\n",
       "      <th>PAK4_gexpr</th>\n",
       "      <th>GNA15_gexpr</th>\n",
       "      <th>ARPP19_gexpr</th>\n",
       "      <th>EAPP_gexpr</th>\n",
       "      <th>MOK_gexpr</th>\n",
       "      <th>MTHFD2_gexpr</th>\n",
       "      <th>TIPARP_gexpr</th>\n",
       "      <th>CASP3_gexpr</th>\n",
       "      <th>...</th>\n",
       "      <th>PDHX_mut</th>\n",
       "      <th>DFFB_mut</th>\n",
       "      <th>FOSL1_mut</th>\n",
       "      <th>ETS1_mut</th>\n",
       "      <th>EBNA1BP2_mut</th>\n",
       "      <th>MYL9_mut</th>\n",
       "      <th>MLLT11_mut</th>\n",
       "      <th>PFKL_mut</th>\n",
       "      <th>FGFR4_mut</th>\n",
       "      <th>SDHB_mut</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CELL_LINE_NAME</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22RV1</th>\n",
       "      <td>7.023759</td>\n",
       "      <td>6.067534</td>\n",
       "      <td>4.318750</td>\n",
       "      <td>3.261427</td>\n",
       "      <td>6.297582</td>\n",
       "      <td>8.313991</td>\n",
       "      <td>5.514912</td>\n",
       "      <td>10.594112</td>\n",
       "      <td>5.222366</td>\n",
       "      <td>6.635925</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23132-87</th>\n",
       "      <td>6.714387</td>\n",
       "      <td>5.695096</td>\n",
       "      <td>4.536146</td>\n",
       "      <td>3.295886</td>\n",
       "      <td>7.021037</td>\n",
       "      <td>8.500080</td>\n",
       "      <td>4.862145</td>\n",
       "      <td>10.609245</td>\n",
       "      <td>6.528668</td>\n",
       "      <td>7.238143</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42-MG-BA</th>\n",
       "      <td>7.752402</td>\n",
       "      <td>5.475753</td>\n",
       "      <td>4.033714</td>\n",
       "      <td>3.176525</td>\n",
       "      <td>7.279671</td>\n",
       "      <td>8.013367</td>\n",
       "      <td>4.957332</td>\n",
       "      <td>11.266705</td>\n",
       "      <td>7.445954</td>\n",
       "      <td>6.312424</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 3432 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                FBXL12_gexpr  PIN1_gexpr  PAK4_gexpr  GNA15_gexpr  \\\n",
       "CELL_LINE_NAME                                                      \n",
       "22RV1               7.023759    6.067534    4.318750     3.261427   \n",
       "23132-87            6.714387    5.695096    4.536146     3.295886   \n",
       "42-MG-BA            7.752402    5.475753    4.033714     3.176525   \n",
       "\n",
       "                ARPP19_gexpr  EAPP_gexpr  MOK_gexpr  MTHFD2_gexpr  \\\n",
       "CELL_LINE_NAME                                                      \n",
       "22RV1               6.297582    8.313991   5.514912     10.594112   \n",
       "23132-87            7.021037    8.500080   4.862145     10.609245   \n",
       "42-MG-BA            7.279671    8.013367   4.957332     11.266705   \n",
       "\n",
       "                TIPARP_gexpr  CASP3_gexpr  ...  PDHX_mut  DFFB_mut  FOSL1_mut  \\\n",
       "CELL_LINE_NAME                             ...                                  \n",
       "22RV1               5.222366     6.635925  ...       1.0       0.0        0.0   \n",
       "23132-87            6.528668     7.238143  ...       0.0       0.0        0.0   \n",
       "42-MG-BA            7.445954     6.312424  ...       0.0       0.0        0.0   \n",
       "\n",
       "                ETS1_mut  EBNA1BP2_mut  MYL9_mut  MLLT11_mut  PFKL_mut  \\\n",
       "CELL_LINE_NAME                                                           \n",
       "22RV1                0.0           0.0       0.0         1.0       0.0   \n",
       "23132-87             0.0           0.0       0.0         0.0       0.0   \n",
       "42-MG-BA             0.0           0.0       0.0         0.0       0.0   \n",
       "\n",
       "                FGFR4_mut  SDHB_mut  \n",
       "CELL_LINE_NAME                       \n",
       "22RV1                 1.0       0.0  \n",
       "23132-87              0.0       0.0  \n",
       "42-MG-BA              0.0       0.0  \n",
       "\n",
       "[3 rows x 3432 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Cell-line gene matrix\\n{21*'='}\")\n",
    "assert len([col for col in cl_gene_mat.columns[1:] if '_gexpr' in col]) == \\\n",
    "    len([col for col in cl_gene_mat.columns[1:] if '_cnvg' in col]) == \\\n",
    "    len([col for col in cl_gene_mat.columns[1:] if '_cnvp' in col]) == \\\n",
    "    len([col for col in cl_gene_mat.columns[1:] if '_mut' in col])\n",
    "cl_gene_mat.set_index('CELL_LINE_NAME', inplace=True)    \n",
    "print(cl_gene_mat.shape)\n",
    "print(f\"unique cell-lines: {len(cl_gene_mat.index.unique())}\")\n",
    "cl_gene_mat.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drug SMILES fingerprint matrix\n",
      "==============================\n",
      "(152, 256)\n",
      "unique drugs: 152\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>246</th>\n",
       "      <th>247</th>\n",
       "      <th>248</th>\n",
       "      <th>249</th>\n",
       "      <th>250</th>\n",
       "      <th>251</th>\n",
       "      <th>252</th>\n",
       "      <th>253</th>\n",
       "      <th>254</th>\n",
       "      <th>255</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DRUG_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1073</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1910</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1913</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 256 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0    1    2    3    4    5    6    7    8    9    ...  246  247  248  \\\n",
       "DRUG_ID                                                    ...                  \n",
       "1073       0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "1910       1    1    0    0    0    0    0    0    0    0  ...    1    0    0   \n",
       "1913       0    1    1    0    1    0    0    0    0    0  ...    0    0    0   \n",
       "\n",
       "         249  250  251  252  253  254  255  \n",
       "DRUG_ID                                     \n",
       "1073       0    0    0    0    0    0    1  \n",
       "1910       0    0    1    0    0    0    1  \n",
       "1913       0    1    1    0    0    0    0  \n",
       "\n",
       "[3 rows x 256 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Drug SMILES fingerprint matrix\\n{30*'='}\")\n",
    "drug_mat.set_index('DRUG_ID', inplace=True)\n",
    "print(drug_mat.shape)\n",
    "print(f\"unique drugs: {len(drug_mat.index.unique())}\")\n",
    "drug_mat.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drug response matrix\n",
      "====================\n",
      "(91991, 5)\n",
      "unique cell-lines: 732\n",
      "unique drugs     : 152\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CELL_LINE_NAME</th>\n",
       "      <th>DRUG_ID</th>\n",
       "      <th>DRUG_NAME</th>\n",
       "      <th>DATASET</th>\n",
       "      <th>LN_IC50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3441054</th>\n",
       "      <td>22RV1</td>\n",
       "      <td>1003</td>\n",
       "      <td>Camptothecin</td>\n",
       "      <td>GDSC2</td>\n",
       "      <td>-3.142631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3459252</th>\n",
       "      <td>22RV1</td>\n",
       "      <td>1004</td>\n",
       "      <td>Vinblastine</td>\n",
       "      <td>GDSC2</td>\n",
       "      <td>-4.459259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3508920</th>\n",
       "      <td>22RV1</td>\n",
       "      <td>1006</td>\n",
       "      <td>Cytarabine</td>\n",
       "      <td>GDSC2</td>\n",
       "      <td>3.826935</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        CELL_LINE_NAME  DRUG_ID     DRUG_NAME DATASET   LN_IC50\n",
       "3441054          22RV1     1003  Camptothecin   GDSC2 -3.142631\n",
       "3459252          22RV1     1004   Vinblastine   GDSC2 -4.459259\n",
       "3508920          22RV1     1006    Cytarabine   GDSC2  3.826935"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Drug response matrix\\n{20*'='}\")\n",
    "print(drm.shape)\n",
    "print(f\"unique cell-lines: {len(drm.CELL_LINE_NAME.unique())}\")\n",
    "print(f\"unique drugs     : {len(drm.DRUG_ID.unique())}\")\n",
    "drm.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create `PyTorch` dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Dataset as PyGDataset\n",
    "\n",
    "class TabTabDataset(PyGDataset):\n",
    "    def __init__(self, cl_mat, drug_mat, drm):\n",
    "        super().__init__()\n",
    "        self.cl_mat = cl_mat\n",
    "        self.drug_mat = drug_mat\n",
    "\n",
    "        drm.reset_index(drop=True, inplace=True)\n",
    "        self.cls = drm['CELL_LINE_NAME']\n",
    "        self.drug_ids = drm['DRUG_ID']\n",
    "        self.drug_names = drm['DRUG_NAME']\n",
    "        self.ic50s = drm['LN_IC50']\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ic50s)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        \"\"\"\n",
    "        Returns a tuple of cell-line-gene features, drug smiles fingerprints \n",
    "        and the corresponding ln(IC50) values for a given index.\n",
    "\n",
    "        Args:\n",
    "            idx (`int`): Index to specify the row in the drug response matrix.  \n",
    "        Returns\n",
    "            `Tuple[np.ndarray, np.ndarray, np.float64]]`: Tuple of cell-line \n",
    "                gene feature values, drug SMILES fingerprints and the \n",
    "                corresponding ln(IC50) target values.\n",
    "        \"\"\"\n",
    "        return (self.cl_mat.loc[self.cls.iloc[idx]], \n",
    "                self.drug_mat.loc[self.drug_ids.iloc[idx]],\n",
    "                self.ic50s.iloc[idx])\n",
    "\n",
    "    def print_summary(self):\n",
    "        print(f\"TabTabDataset Summary\")\n",
    "        print(21*'=')\n",
    "        print(f\"# observations :\", len(self.ic50s))\n",
    "        print(f\"# cell-lines   :\", len(np.unique(self.cls)))\n",
    "        print(f\"# drugs        :\", len(np.unique(self.drug_names)))\n",
    "        print(f\"# genes        :\", len([col for col in self.cl_mat.columns[1:] if '_cnvg' in col]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TabTabDataset Summary\n",
      "=====================\n",
      "# observations : 91991\n",
      "# cell-lines   : 732\n",
      "# drugs        : 152\n",
      "# genes        : 858\n"
     ]
    }
   ],
   "source": [
    "tab_tab_dataset = TabTabDataset(cl_mat=cl_gene_mat, drug_mat=drug_mat, drm=drm)\n",
    "tab_tab_dataset.print_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self, batch_size, lr, train_ratio, val_ratio, num_epochs):\n",
    "        self.BATCH_SIZE = batch_size\n",
    "        self.LR = lr\n",
    "        self.TRAIN_RATIO = train_ratio\n",
    "        self.TEST_VAL_RATIO = 1-self.TRAIN_RATIO\n",
    "        self.VAL_RATIO = val_ratio\n",
    "        self.NUM_EPOCHS = num_epochs\n",
    "        self.RANDOM_SEED = 12345      \n",
    "\n",
    "args = Args(batch_size=1_000, \n",
    "            lr=0.0001, \n",
    "            train_ratio=0.8, \n",
    "            val_ratio=0.5, \n",
    "            num_epochs=300)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create `DataLoader` datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CELL_LINE_NAME    False\n",
      "DRUG_ID           False\n",
      "DRUG_NAME         False\n",
      "DATASET           False\n",
      "LN_IC50           False\n",
      "dtype: bool\n",
      "FBXL12_gexpr    False\n",
      "PIN1_gexpr      False\n",
      "PAK4_gexpr      False\n",
      "GNA15_gexpr     False\n",
      "ARPP19_gexpr    False\n",
      "                ...  \n",
      "MYL9_mut        False\n",
      "MLLT11_mut      False\n",
      "PFKL_mut        False\n",
      "FGFR4_mut       False\n",
      "SDHB_mut        False\n",
      "Length: 3432, dtype: bool\n",
      "0      False\n",
      "1      False\n",
      "2      False\n",
      "3      False\n",
      "4      False\n",
      "       ...  \n",
      "251    False\n",
      "252    False\n",
      "253    False\n",
      "254    False\n",
      "255    False\n",
      "Length: 256, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "print(drm.isna().any())\n",
    "print(cl_gene_mat.isna().any())\n",
    "print(drug_mat.isna().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FBXL12_gexpr    0\n",
       "PIN1_gexpr      0\n",
       "PAK4_gexpr      0\n",
       "GNA15_gexpr     0\n",
       "ARPP19_gexpr    0\n",
       "               ..\n",
       "PFKL_gexpr      0\n",
       "FGFR4_gexpr     0\n",
       "SDHB_gexpr      0\n",
       "FBXL12_cnvg     0\n",
       "PIN1_cnvg       0\n",
       "Length: 860, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl_gene_mat.isna().sum().head(860)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set.shape: (73592, 5)\n",
      "test_set.shape: (9199, 5)\n",
      "val_set.shape: (9200, 5)\n",
      "\n",
      "train_dataset\n",
      "TabTabDataset Summary\n",
      "=====================\n",
      "# observations : 73592\n",
      "# cell-lines   : 732\n",
      "# drugs        : 152\n",
      "# genes        : 858\n",
      "\n",
      "test_dataset\n",
      "TabTabDataset Summary\n",
      "=====================\n",
      "# observations : 9199\n",
      "# cell-lines   : 732\n",
      "# drugs        : 152\n",
      "# genes        : 858\n",
      "\n",
      "val_dataset\n",
      "TabTabDataset Summary\n",
      "=====================\n",
      "# observations : 9200\n",
      "# cell-lines   : 732\n",
      "# drugs        : 152\n",
      "# genes        : 858\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def _collate_tab_tab(samples):\n",
    "    cls, drugs, ic50s = map(list, zip(*samples))\n",
    "    cls = [torch.tensor(cl, dtype=torch.float64) for cl in cls]\n",
    "    drugs = [torch.tensor(drug, dtype=torch.float64) for drug in drugs]\n",
    "    # print(\"\\nCELL-LINES: \", cls[0])\n",
    "    # print(\"\\nDRUG:\", drugs[0])\n",
    "    # print(\"\\nIC50: \", ic50s[0])\n",
    "    \n",
    "    return torch.stack(cls, 0), torch.stack(drugs, 0), torch.tensor(ic50s)\n",
    "\n",
    "def create_datasets(drm, cl_mat, drug_mat):\n",
    "    train_set, test_val_set = train_test_split(drm, test_size=args.TEST_VAL_RATIO, random_state=args.RANDOM_SEED, stratify=drm['CELL_LINE_NAME'])\n",
    "    test_set, val_set = train_test_split(test_val_set, test_size=args.VAL_RATIO, random_state=args.RANDOM_SEED, stratify=test_val_set['CELL_LINE_NAME'])\n",
    "\n",
    "    print(\"train_set.shape:\", train_set.shape)\n",
    "    print(\"test_set.shape:\", test_set.shape)\n",
    "    print(\"val_set.shape:\", val_set.shape)\n",
    "\n",
    "    train_dataset = TabTabDataset(cl_mat=cl_mat, drug_mat=drug_mat, drm=train_set)\n",
    "    test_dataset = TabTabDataset(cl_mat=cl_mat, drug_mat=drug_mat, drm=test_set)\n",
    "    val_dataset = TabTabDataset(cl_mat=cl_mat, drug_mat=drug_mat, drm=val_set)\n",
    "\n",
    "    print(\"\\ntrain_dataset\"); train_dataset.print_summary()\n",
    "    print(\"\\ntest_dataset\"); test_dataset.print_summary()\n",
    "    print(\"\\nval_dataset\"); val_dataset.print_summary()\n",
    "\n",
    "    train_loader = DataLoader(dataset=train_dataset, batch_size=args.BATCH_SIZE, shuffle=True, collate_fn=_collate_tab_tab)\n",
    "    test_loader = DataLoader(dataset=test_dataset, batch_size=args.BATCH_SIZE, shuffle=True, collate_fn=_collate_tab_tab)\n",
    "    val_loader = DataLoader(dataset=val_dataset, batch_size=args.BATCH_SIZE, shuffle=True, collate_fn=_collate_tab_tab)\n",
    "\n",
    "    return train_loader, test_loader, val_loader\n",
    "\n",
    "train_loader, test_loader, val_loader = create_datasets(drm, cl_gene_mat, drug_mat)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of batches per dataset:\n",
      "  train : 74\n",
      "  test  : 10\n",
      "  val   : 10\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of batches per dataset:\")\n",
    "print(f\"  train : {len(train_loader)}\")\n",
    "print(f\"  test  : {len(test_loader)}\")\n",
    "print(f\"  val   : {len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(FBXL12_gexpr    7.023759\n",
       " PIN1_gexpr      6.067534\n",
       " PAK4_gexpr      4.318750\n",
       " GNA15_gexpr     3.261427\n",
       " ARPP19_gexpr    6.297582\n",
       "                   ...   \n",
       " MYL9_mut        0.000000\n",
       " MLLT11_mut      1.000000\n",
       " PFKL_mut        0.000000\n",
       " FGFR4_mut       1.000000\n",
       " SDHB_mut        0.000000\n",
       " Name: 22RV1, Length: 3432, dtype: float64,\n",
       " 0      1\n",
       " 1      0\n",
       " 2      0\n",
       " 3      0\n",
       " 4      0\n",
       "       ..\n",
       " 251    1\n",
       " 252    0\n",
       " 253    0\n",
       " 254    0\n",
       " 255    0\n",
       " Name: 1004, Length: 256, dtype: int64,\n",
       " -4.459259)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tab_tab_dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1:\n",
      "=======\n",
      "torch.Size([1000, 3432])\n",
      "torch.Size([1000, 256])\n",
      "torch.Size([1000])\n",
      "Step 2:\n",
      "=======\n",
      "torch.Size([1000, 3432])\n",
      "torch.Size([1000, 256])\n",
      "torch.Size([1000])\n",
      "Step 3:\n",
      "=======\n",
      "torch.Size([1000, 3432])\n",
      "torch.Size([1000, 256])\n",
      "torch.Size([1000])\n",
      "... step 10\n",
      "... step 20\n",
      "... step 30\n",
      "... step 40\n",
      "... step 50\n",
      "... step 60\n",
      "... step 70\n",
      "Step 74:\n",
      "=======\n",
      "torch.Size([592, 3432])\n",
      "torch.Size([592, 256])\n",
      "torch.Size([592])\n"
     ]
    }
   ],
   "source": [
    "for step, data in enumerate(train_loader):\n",
    "    if (step > 2) & (step < len(train_loader)-1):\n",
    "        if step % 10 == 0: \n",
    "            print(\"... step\", step) \n",
    "        continue\n",
    "    else:\n",
    "        cl_mat, drug_mat, ic50s = data\n",
    "        print(f'Step {step + 1}:')\n",
    "        print(f'=======')    \n",
    "        print(cl_mat.shape)\n",
    "        print(drug_mat.shape)\n",
    "        print(ic50s.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from time import sleep\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "\n",
    "class BuildModel:\n",
    "    def __init__(self, model, criterion, optimizer, num_epochs, \n",
    "        train_loader, test_loader, val_loader, device):\n",
    "        self.train_losses = []\n",
    "        self.test_losses = []\n",
    "        self.val_losses = []\n",
    "        self.train_loader = train_loader \n",
    "        self.test_loader = test_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.num_epochs = num_epochs\n",
    "        self.model = model \n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer \n",
    "        self.device = device\n",
    "\n",
    "    def train(self, loader): \n",
    "        train_epoch_losses, val_epoch_losses = [], []\n",
    "        all_batch_losses = [] # TODO: this is just for monitoring\n",
    "        n_batches = len(loader)\n",
    "        for epoch in range(self.num_epochs): \n",
    "            self.model.train()\n",
    "            batch_losses = []\n",
    "            for data in tqdm(loader, desc='Iter', position=0, leave=True):\n",
    "                sleep(0.01)\n",
    "                cl, dr, ic50 = data\n",
    "                cl, dr, ic50 = cl.to(self.device), dr.to(self.device), ic50.to(self.device)\n",
    "                self.optimizer.zero_grad()                \n",
    "\n",
    "                preds = self.model(cl.float(), dr.float()).unsqueeze(1) # TODO: unsqueeze can be added to forward\n",
    "                loss = self.criterion(preds, ic50.view(-1,1).float())\n",
    "                batch_losses.append(loss)\n",
    "\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "            all_batch_losses.append(batch_losses) # TODO: this is just for monitoring\n",
    "            total_epoch_loss = sum(batch_losses)\n",
    "            train_epoch_losses.append(total_epoch_loss / n_batches)\n",
    "\n",
    "            # TODO: add also the other metrics per epoch\n",
    "            mse, _, _, _, _ = self.validate(self.val_loader)\n",
    "            val_epoch_losses.append(mse)\n",
    "\n",
    "            if epoch % 25 == 0:\n",
    "                print(\"=====Epoch \", epoch)\n",
    "                print(f\"Train      | MSE: {train_epoch_losses[-1]:2.5f}\")\n",
    "                print(f\"Validation | MSE: {mse:2.5f}\")\n",
    "\n",
    "        return train_epoch_losses, val_epoch_losses\n",
    "\n",
    "    def validate(self, loader):\n",
    "        self.model.eval()\n",
    "        y_true, y_pred = [], []\n",
    "        total_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for data in tqdm(loader, desc='Iter', position=0, leave=True):\n",
    "                sleep(0.01)\n",
    "                cl, dr, ic50 = data\n",
    "\n",
    "                preds = self.model(cl.float(), dr.float()).unsqueeze(1)\n",
    "                ic50 = ic50.to(self.device)\n",
    "                total_loss += self.criterion(preds, ic50.view(-1,1).float())\n",
    "                # total_loss += F.mse_loss(preds, ic50.view(-1, 1).float(), reduction='sum')\n",
    "                y_true.append(ic50.view(-1, 1))\n",
    "                y_pred.append(preds)\n",
    "        \n",
    "        y_true = torch.cat(y_true, dim=0)\n",
    "        y_pred = torch.cat(y_pred, dim=0)\n",
    "        mse = total_loss / len(loader)\n",
    "        rmse = torch.sqrt(mse)\n",
    "        mae = mean_absolute_error(y_true.cpu(), y_pred.cpu())\n",
    "        r2 = r2_score(y_true.cpu(), y_pred.cpu())\n",
    "        pearson_corr_coef, _ = pearsonr(y_true.cpu().numpy().flatten(), \n",
    "                                        y_pred.cpu().numpy().flatten())\n",
    "\n",
    "        return mse, rmse, mae, r2, pearson_corr_coef\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cpu\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "\n",
    "class TabTabModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TabTabModel, self).__init__()\n",
    "        self.cell_branch = nn.Sequential(\n",
    "            nn.Linear(3432, 516),\n",
    "            nn.BatchNorm1d(516),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.1),\n",
    "            nn.Linear(516, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.1),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU()         \n",
    "        )\n",
    "\n",
    "        self.drug_branch = nn.Sequential(\n",
    "            nn.Linear(256, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.1),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU()          \n",
    "        )\n",
    "\n",
    "        self.fcn = nn.Sequential(\n",
    "            nn.Linear(2*128, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(p=0.1),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(p=0.1),\n",
    "            nn.Linear(64, 1)\n",
    "        )     \n",
    "\n",
    "    def forward(self, cell, drug):\n",
    "        cell_emb = self.cell_branch(cell)  # Create cell gene vector embedding.\n",
    "        drug_emb = self.drug_branch(drug)  # Create compound vector embedding.\n",
    "        # print(\"cell_emb: \", cell_emb.shape)\n",
    "        # print(\"drug_emb: \", drug_emb.shape)\n",
    "\n",
    "        concat = torch.cat([cell_emb, drug_emb], 1)\n",
    "        # print(concat.shape)\n",
    "        # print(concat)\n",
    "\n",
    "        # x_dim_batch, y_dim_branch, z_dim_features = concat.shape[0], concat.shape[1], concat.shape[2]\n",
    "        # concat = torch.reshape(concat, (x_dim_batch, y_dim_branch*z_dim_features))\n",
    "        \n",
    "        y_pred = self.fcn(concat)\n",
    "        y_pred = y_pred.reshape(y_pred.shape[0])\n",
    "        return y_pred\n",
    "\n",
    "torch.manual_seed(args.RANDOM_SEED)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"device:\", device)\n",
    "\n",
    "model = TabTabModel().to(device)\n",
    "loss_func = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=args.LR)\n",
    "\n",
    "build_model = BuildModel(model, loss_func, optimizer, args.NUM_EPOCHS, \n",
    "                         train_loader, test_loader, val_loader,\n",
    "                         device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter: 100%|██████████| 74/74 [01:37<00:00,  1.32s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:23<00:00,  2.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====Epoch  0\n",
      "Train      | MSE: 10.92296\n",
      "Validation | MSE: 7.30963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter: 100%|██████████| 74/74 [17:23<00:00, 14.10s/it]  \n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.08s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:28<00:00,  1.20s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:28<00:00,  1.20s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.03s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:32<00:00,  1.26s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:11<00:00,  1.20s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:30<00:00,  1.23s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.00s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:28<00:00,  1.20s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:29<00:00,  1.21s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:29<00:00,  1.21s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:28<00:00,  1.20s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:29<00:00,  1.21s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:29<00:00,  1.21s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.00it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:32<00:00,  1.25s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.04it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:28<00:00,  1.19s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:28<00:00,  1.20s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:28<00:00,  1.19s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.00it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:28<00:00,  1.20s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.00s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:28<00:00,  1.20s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:28<00:00,  1.20s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.00s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:29<00:00,  1.20s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.00s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:28<00:00,  1.20s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:28<00:00,  1.20s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:28<00:00,  1.20s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:28<00:00,  1.20s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:29<00:00,  1.21s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:29<00:00,  1.21s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====Epoch  25\n",
      "Train      | MSE: 1.31992\n",
      "Validation | MSE: 1.23547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter: 100%|██████████| 74/74 [01:28<00:00,  1.20s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.00s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:29<00:00,  1.20s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:29<00:00,  1.21s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.06s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:30<00:00,  1.22s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:28<00:00,  1.19s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.04s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:29<00:00,  1.20s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:29<00:00,  1.21s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.00s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:29<00:00,  1.20s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.02s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:29<00:00,  1.20s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:29<00:00,  1.21s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:28<00:00,  1.20s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.04s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:28<00:00,  1.20s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:28<00:00,  1.20s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.00s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:30<00:00,  1.22s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.02it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:25<00:00,  1.15s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.03it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:25<00:00,  1.16s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.02it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:25<00:00,  1.16s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.03it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:25<00:00,  1.16s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:29<00:00,  1.21s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.03it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:25<00:00,  1.15s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.03it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:29<00:00,  1.21s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.03s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:29<00:00,  1.21s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.07s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:28<00:00,  1.20s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:28<00:00,  1.20s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:29<00:00,  1.20s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====Epoch  50\n",
      "Train      | MSE: 1.08509\n",
      "Validation | MSE: 1.00775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter: 100%|██████████| 74/74 [01:29<00:00,  1.21s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:29<00:00,  1.21s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:28<00:00,  1.20s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.03s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:29<00:00,  1.21s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:28<00:00,  1.20s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:28<00:00,  1.20s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.02s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:28<00:00,  1.19s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.03it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:25<00:00,  1.15s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.03it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:25<00:00,  1.15s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.02it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:29<00:00,  1.20s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.03it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:28<00:00,  1.19s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:29<00:00,  1.20s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:29<00:00,  1.21s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.00s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:28<00:00,  1.20s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:29<00:00,  1.21s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.02s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:30<00:00,  1.22s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:28<00:00,  1.20s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:29<00:00,  1.21s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:29<00:00,  1.21s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.03s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:29<00:00,  1.20s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.02s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:29<00:00,  1.21s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:29<00:00,  1.21s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.04s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:29<00:00,  1.21s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:29<00:00,  1.20s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:28<00:00,  1.20s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====Epoch  75\n",
      "Train      | MSE: 0.98334\n",
      "Validation | MSE: 0.96934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter: 100%|██████████| 74/74 [01:29<00:00,  1.21s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:28<00:00,  1.20s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.00s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:28<00:00,  1.20s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:29<00:00,  1.21s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.00s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:28<00:00,  1.20s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.00it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.19s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.00it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:28<00:00,  1.19s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:28<00:00,  1.19s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.06it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:23<00:00,  1.13s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.07it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:22<00:00,  1.12s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.07it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:22<00:00,  1.12s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.02it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.03s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:28<00:00,  1.19s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:11<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:28<00:00,  1.20s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.03s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:25<00:00,  1.16s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.07it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:25<00:00,  1.15s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.04it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:24<00:00,  1.15s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.06it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:25<00:00,  1.15s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.02it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.06it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:30<00:00,  1.23s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:34<00:00,  1.27s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.02it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:11<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:24<00:00,  1.14s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====Epoch  100\n",
      "Train      | MSE: 0.92735\n",
      "Validation | MSE: 0.91169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter: 100%|██████████| 74/74 [01:29<00:00,  1.21s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:30<00:00,  1.22s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.00s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.19s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.00it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:28<00:00,  1.19s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.00it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.19s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.00it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:28<00:00,  1.20s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:11<00:00,  1.10s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:31<00:00,  1.24s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.00s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.19s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.00it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.19s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.03s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:28<00:00,  1.19s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.00it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:31<00:00,  1.24s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.06s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:37<00:00,  1.32s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.03s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:28<00:00,  1.19s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.04it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:24<00:00,  1.14s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.05it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:23<00:00,  1.13s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.06it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:23<00:00,  1.13s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.06it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.00s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:28<00:00,  1.20s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:28<00:00,  1.20s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.00it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:28<00:00,  1.19s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.16s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.07it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.00it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====Epoch  125\n",
      "Train      | MSE: 0.87510\n",
      "Validation | MSE: 0.92339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.05it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:24<00:00,  1.15s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.00s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:24<00:00,  1.14s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.06it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:28<00:00,  1.19s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:23<00:00,  1.13s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.00s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:28<00:00,  1.19s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:24<00:00,  1.15s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.07it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:25<00:00,  1.15s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.07it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.00s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:25<00:00,  1.16s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.06it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:25<00:00,  1.16s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.02s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:25<00:00,  1.15s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.07it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.00s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.00s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.06it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:24<00:00,  1.14s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.00s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.19s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.06it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:25<00:00,  1.15s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====Epoch  150\n",
      "Train      | MSE: 0.83066\n",
      "Validation | MSE: 0.88861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.19s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.00it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:25<00:00,  1.16s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.07it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:25<00:00,  1.16s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.00it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:24<00:00,  1.14s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.04it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:28<00:00,  1.19s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.00it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:25<00:00,  1.16s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.07it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.00it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.07it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:24<00:00,  1.14s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.00s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.19s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.05it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:23<00:00,  1.12s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.06it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:23<00:00,  1.13s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.00it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.19s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.03it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.00it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:25<00:00,  1.16s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.04it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:25<00:00,  1.16s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.02s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.00it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:24<00:00,  1.14s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====Epoch  175\n",
      "Train      | MSE: 0.79286\n",
      "Validation | MSE: 0.85819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.00it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.06it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:23<00:00,  1.13s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.00s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.19s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:24<00:00,  1.15s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.06it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:24<00:00,  1.14s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.07it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.00it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.16s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.05it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:25<00:00,  1.15s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.19s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:23<00:00,  1.13s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.02it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.16s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:24<00:00,  1.14s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.03it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:25<00:00,  1.16s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.04s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.00it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.00s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:25<00:00,  1.15s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====Epoch  200\n",
      "Train      | MSE: 0.76515\n",
      "Validation | MSE: 0.86072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter: 100%|██████████| 74/74 [01:25<00:00,  1.15s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.00s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.03it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:25<00:00,  1.16s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.07it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:24<00:00,  1.14s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.02it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.19s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.00s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.02it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.06it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:24<00:00,  1.14s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.00s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:23<00:00,  1.13s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.05it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:22<00:00,  1.12s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.05it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.00s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:25<00:00,  1.16s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.06it/s]\n",
      "Iter: 100%|██████████| 74/74 [02:53<00:00,  2.34s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.19s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.02s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:30<00:00,  1.22s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.07s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:30<00:00,  1.23s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.03s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:29<00:00,  1.21s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.06it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.16s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====Epoch  225\n",
      "Train      | MSE: 0.73852\n",
      "Validation | MSE: 0.82977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.03it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:22<00:00,  1.12s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.05it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:22<00:00,  1.12s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.07it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:22<00:00,  1.12s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.06it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:22<00:00,  1.12s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.05it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:22<00:00,  1.12s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.06it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:22<00:00,  1.12s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.05it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:23<00:00,  1.13s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.06it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:23<00:00,  1.13s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.06it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:22<00:00,  1.12s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.05it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.05s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.16s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.05it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:23<00:00,  1.13s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.04s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:30<00:00,  1.22s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.00it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:25<00:00,  1.15s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.05it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:22<00:00,  1.12s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.06it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:22<00:00,  1.12s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.06it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:22<00:00,  1.12s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.07it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:22<00:00,  1.11s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.06it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:22<00:00,  1.12s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.00it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:28<00:00,  1.19s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:31<00:00,  1.24s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.07s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.02it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.06it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:22<00:00,  1.12s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====Epoch  250\n",
      "Train      | MSE: 0.71375\n",
      "Validation | MSE: 0.83597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter: 100%|██████████| 74/74 [01:22<00:00,  1.11s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.06it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:23<00:00,  1.13s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.07it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:22<00:00,  1.12s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.05it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:22<00:00,  1.12s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.08it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:36<00:00,  1.30s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.03it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:31<00:00,  1.23s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.05it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:23<00:00,  1.13s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.06it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:24<00:00,  1.14s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.04it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:23<00:00,  1.13s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.04it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:23<00:00,  1.13s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.06it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:23<00:00,  1.13s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.05it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:24<00:00,  1.14s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.05it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:23<00:00,  1.13s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.05it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:24<00:00,  1.14s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.05s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.03s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.02it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.02it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.02it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.05it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:25<00:00,  1.16s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.02it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.03it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====Epoch  275\n",
      "Train      | MSE: 0.69882\n",
      "Validation | MSE: 0.81370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.02it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.02it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.02it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.00s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.02it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.02it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:18<00:00,  1.06s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.02it/s]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 mse      rmse       mae        r2         r\n",
      "----------  --------  --------  --------  --------  --------\n",
      "train       0.450149  0.670932  0.51781   0.938216  0.968843\n",
      "validation  0.811576  0.900875  0.662914  0.889404  0.943088\n",
      "test        0.83026   0.911186  0.669223  0.886715  0.941691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_losses, val_losses = build_model.train(build_model.train_loader)\n",
    "\n",
    "tr_mse, tr_rmse, tr_mae, tr_r2, tr_r = build_model.validate(build_model.train_loader)\n",
    "val_mse, val_rmse, val_mae, val_r2, val_r = build_model.validate(build_model.val_loader)\n",
    "te_mse, te_rmse, te_mae, te_r2, te_r = build_model.validate(build_model.test_loader)\n",
    "\n",
    "results = tabulate(\n",
    "    [\n",
    "        ['mse', 'rmse', 'mae', 'r2', 'r'],\n",
    "        ['train', tr_mse, tr_rmse, tr_mae, tr_r2, tr_r],\n",
    "        ['validation', val_mse, val_rmse, val_mae, val_r2, val_r],\n",
    "        ['test', te_mse, te_rmse, te_mae, te_r2, te_r]\n",
    "    ], headers='firstrow')\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "n_epochs = 100\n",
    "    mse     rmse       mae        r2         r\n",
    "-------  -------  --------  --------  --------\n",
    "1.34979  1.1618   0.580942  0.814719  0.92687\n",
    "2.09012  1.44572  0.981567  0.709278  0.858571\n",
    "2.14415  1.46429  0.983369  0.709229  0.857674\n",
    "\n",
    "n_epochs = 300\n",
    "                 mse      rmse       mae        r2         r\n",
    "----------  --------  --------  --------  --------  --------\n",
    "train       0.450149  0.670932  0.51781   0.938216  0.968843\n",
    "validation  0.811576  0.900875  0.662914  0.889404  0.943088\n",
    "test        0.83026   0.911186  0.669223  0.886715  0.941691\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 mse      rmse       mae        r2         r\n",
      "----------  --------  --------  --------  --------  --------\n",
      "train       0.450149  0.670932  0.51781   0.938216  0.968843\n",
      "validation  0.811576  0.900875  0.662914  0.889404  0.943088\n",
      "test        0.83026   0.911186  0.669223  0.886715  0.941691\n"
     ]
    }
   ],
   "source": [
    "results = tabulate(\n",
    "    [\n",
    "        ['mse', 'rmse', 'mae', 'r2', 'r'],\n",
    "        ['train', tr_mse, tr_rmse, tr_mae, tr_r2, tr_r],\n",
    "        ['validation', val_mse, val_rmse, val_mae, val_r2, val_r],\n",
    "        ['test', te_mse, te_rmse, te_mae, te_r2, te_r]\n",
    "    ], headers='firstrow')\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA on Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([loss.item() for loss in train_losses], c='C0', label='train');\n",
    "plt.plot([loss.item() for loss in val_losses], c='C1', label='validation');\n",
    "plt.legend();\n",
    "plt.ticklabel_format(style='plain');\n",
    "plt.xlabel(\"Epoch\");\n",
    "plt.ylabel(\"Loss (MSE)\");\n",
    "plt.title(\"TabTab Model Performance\");\n",
    "plt.xlim(0, args.NUM_EPOCHS, 1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([np.log(loss.item()) for loss in train_losses], c='C0', label='train');\n",
    "plt.plot([np.log(loss.item()) for loss in val_losses], c='C1', label='validation');\n",
    "plt.legend();\n",
    "plt.ticklabel_format(style='plain');\n",
    "plt.xlim(0, args.NUM_EPOCHS, 1);\n",
    "plt.xlabel(\"Epoch\");\n",
    "plt.ylabel(\"log(loss)\");\n",
    "plt.title(\"TabTab Model Performance\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__TODOs__:\n",
    "- [ ] add early stopping \n",
    "- [ ] parallelize by adding do separate `.py` files\n",
    "- [ ] increase train data by including GDSC2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(build_model.model.state_dict(), '../../datasets/models/TabTab_v1.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 95264\n",
      "-rw-r--r--  1 cwoest  staff   8.1M Sep 28 13:52 Model2CnvGistic__cnv_gistic.pkl\n",
      "-rw-r--r--  1 cwoest  staff   8.1M Sep 28 14:37 Model2CnvGistic__cnv_picnic.pkl\n",
      "-rw-r--r--  1 cwoest  staff   7.8M Nov 11 19:03 TabTab_v1.pkl\n",
      "-rw-r--r--  1 cwoest  staff   7.8M Nov 11 19:04 TabTab_v1.pt\n",
      "-rw-r--r--  1 cwoest  staff   8.1M Sep 28 13:12 model2.pkl\n",
      "-rw-r--r--  1 cwoest  staff   1.3M Aug 24 16:00 simpleNN\n",
      "-rw-r--r--  1 cwoest  staff   1.3M Aug 24 15:58 simpleNN.pkl\n",
      "-rw-r--r--  1 cwoest  staff   4.0M Aug 24 16:03 simpleNN_extensive.pkl\n"
     ]
    }
   ],
   "source": [
    "ls -lh ../../datasets/models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TabTabModel(\n",
       "  (cell_branch): Sequential(\n",
       "    (0): Linear(in_features=3432, out_features=516, bias=True)\n",
       "    (1): BatchNorm1d(516, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.1, inplace=False)\n",
       "    (4): Linear(in_features=516, out_features=256, bias=True)\n",
       "    (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU()\n",
       "    (7): Dropout(p=0.1, inplace=False)\n",
       "    (8): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (9): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): ReLU()\n",
       "  )\n",
       "  (drug_branch): Sequential(\n",
       "    (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.1, inplace=False)\n",
       "    (4): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (5): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU()\n",
       "  )\n",
       "  (fcn): Sequential(\n",
       "    (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ELU(alpha=1.0)\n",
       "    (3): Dropout(p=0.1, inplace=False)\n",
       "    (4): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (5): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ELU(alpha=1.0)\n",
       "    (7): Dropout(p=0.1, inplace=False)\n",
       "    (8): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model = TabTabModel()\n",
    "loaded_model.load_state_dict(torch.load('../../datasets/models/TabTab_v1.pt'))\n",
    "loaded_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.2950, grad_fn=<AddBackward0>)\n",
      "tensor(10.2950, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[tensor(0.9803, grad_fn=<MseLossBackward0>),\n",
       " tensor(2.1797, grad_fn=<MseLossBackward0>),\n",
       " tensor(3.0829, grad_fn=<MseLossBackward0>),\n",
       " tensor(2.1547, grad_fn=<MseLossBackward0>),\n",
       " tensor(1.8975, grad_fn=<MseLossBackward0>)]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outs = []\n",
    "os = 0\n",
    "for i in range(5):\n",
    "\n",
    "    loss = nn.MSELoss()\n",
    "    input = torch.randn(3, 5, requires_grad=True)\n",
    "    target = torch.randn(3, 5)\n",
    "    output = loss(input, target)\n",
    "    outs.append(output)\n",
    "    os += output\n",
    "    output.backward()\n",
    "print(sum(outs))\n",
    "print(os)\n",
    "outs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(13.1052, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c78b81650a0bd32063743affb6953ff71b1a0dba806fbca9e2db842718495748"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('master-thesis-log')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
