{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pickle\n",
    "import torch\n",
    "import copy\n",
    "import torch.nn          as nn\n",
    "import numpy             as np\n",
    "import pandas            as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn           as sns\n",
    "\n",
    "from tqdm                   import tqdm \n",
    "from typing                 import List\n",
    "from tabulate               import tabulate\n",
    "from torch.utils.data       import Dataset, DataLoader\n",
    "from torch_geometric.loader import DataLoader as PyG_Dataloader\n",
    "\n",
    "from config import PATH_SUMMARY_DATASETS\n",
    "\n",
    "torch.manual_seed(42)\n",
    "sns.set_theme(style=\"white\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Experiments on the `TabTab` approach\n",
    "\n",
    "In this notebook we are going to expirment the approach of \n",
    "- having the cell-line branch using tabular input (`Tab`)\n",
    "- having the drug branch using tabular input (`Tab`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "WITHOUT_MISSING_FOLDER = '/without_missing/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Root datasets\n",
    "\n",
    "- The final datasets have been created in `15_summary_datasets.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the cell-line gene graphs.\n",
    "with open(f'{PATH_SUMMARY_DATASETS}{WITHOUT_MISSING_FOLDER}cell_line_gene_matrix.pkl', 'rb') as f:\n",
    "    cl_gene_mat = pickle.load(f)\n",
    "\n",
    "# Reading the drug SMILES fingerprint table.\n",
    "with open(f'{PATH_SUMMARY_DATASETS}drug_smiles_fingerprints_matrix.pkl', 'rb') as f:\n",
    "    drug_mat = pickle.load(f)\n",
    "\n",
    "# Reading the drug response matrix.\n",
    "with open(f'{PATH_SUMMARY_DATASETS}{WITHOUT_MISSING_FOLDER}drug_response_matrix__gdsc2.pkl', 'rb') as f: \n",
    "    drm = pickle.load(f)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell-line gene matrix\n",
      "=====================\n",
      "(732, 3432)\n",
      "unique cell-lines: 732\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FBXL12_gexpr</th>\n",
       "      <th>PIN1_gexpr</th>\n",
       "      <th>PAK4_gexpr</th>\n",
       "      <th>GNA15_gexpr</th>\n",
       "      <th>ARPP19_gexpr</th>\n",
       "      <th>EAPP_gexpr</th>\n",
       "      <th>MOK_gexpr</th>\n",
       "      <th>MTHFD2_gexpr</th>\n",
       "      <th>TIPARP_gexpr</th>\n",
       "      <th>CASP3_gexpr</th>\n",
       "      <th>...</th>\n",
       "      <th>PDHX_mut</th>\n",
       "      <th>DFFB_mut</th>\n",
       "      <th>FOSL1_mut</th>\n",
       "      <th>ETS1_mut</th>\n",
       "      <th>EBNA1BP2_mut</th>\n",
       "      <th>MYL9_mut</th>\n",
       "      <th>MLLT11_mut</th>\n",
       "      <th>PFKL_mut</th>\n",
       "      <th>FGFR4_mut</th>\n",
       "      <th>SDHB_mut</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CELL_LINE_NAME</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22RV1</th>\n",
       "      <td>7.023759</td>\n",
       "      <td>6.067534</td>\n",
       "      <td>4.318750</td>\n",
       "      <td>3.261427</td>\n",
       "      <td>6.297582</td>\n",
       "      <td>8.313991</td>\n",
       "      <td>5.514912</td>\n",
       "      <td>10.594112</td>\n",
       "      <td>5.222366</td>\n",
       "      <td>6.635925</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23132-87</th>\n",
       "      <td>6.714387</td>\n",
       "      <td>5.695096</td>\n",
       "      <td>4.536146</td>\n",
       "      <td>3.295886</td>\n",
       "      <td>7.021037</td>\n",
       "      <td>8.500080</td>\n",
       "      <td>4.862145</td>\n",
       "      <td>10.609245</td>\n",
       "      <td>6.528668</td>\n",
       "      <td>7.238143</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42-MG-BA</th>\n",
       "      <td>7.752402</td>\n",
       "      <td>5.475753</td>\n",
       "      <td>4.033714</td>\n",
       "      <td>3.176525</td>\n",
       "      <td>7.279671</td>\n",
       "      <td>8.013367</td>\n",
       "      <td>4.957332</td>\n",
       "      <td>11.266705</td>\n",
       "      <td>7.445954</td>\n",
       "      <td>6.312424</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 3432 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                FBXL12_gexpr  PIN1_gexpr  PAK4_gexpr  GNA15_gexpr  \\\n",
       "CELL_LINE_NAME                                                      \n",
       "22RV1               7.023759    6.067534    4.318750     3.261427   \n",
       "23132-87            6.714387    5.695096    4.536146     3.295886   \n",
       "42-MG-BA            7.752402    5.475753    4.033714     3.176525   \n",
       "\n",
       "                ARPP19_gexpr  EAPP_gexpr  MOK_gexpr  MTHFD2_gexpr  \\\n",
       "CELL_LINE_NAME                                                      \n",
       "22RV1               6.297582    8.313991   5.514912     10.594112   \n",
       "23132-87            7.021037    8.500080   4.862145     10.609245   \n",
       "42-MG-BA            7.279671    8.013367   4.957332     11.266705   \n",
       "\n",
       "                TIPARP_gexpr  CASP3_gexpr  ...  PDHX_mut  DFFB_mut  FOSL1_mut  \\\n",
       "CELL_LINE_NAME                             ...                                  \n",
       "22RV1               5.222366     6.635925  ...       1.0       0.0        0.0   \n",
       "23132-87            6.528668     7.238143  ...       0.0       0.0        0.0   \n",
       "42-MG-BA            7.445954     6.312424  ...       0.0       0.0        0.0   \n",
       "\n",
       "                ETS1_mut  EBNA1BP2_mut  MYL9_mut  MLLT11_mut  PFKL_mut  \\\n",
       "CELL_LINE_NAME                                                           \n",
       "22RV1                0.0           0.0       0.0         1.0       0.0   \n",
       "23132-87             0.0           0.0       0.0         0.0       0.0   \n",
       "42-MG-BA             0.0           0.0       0.0         0.0       0.0   \n",
       "\n",
       "                FGFR4_mut  SDHB_mut  \n",
       "CELL_LINE_NAME                       \n",
       "22RV1                 1.0       0.0  \n",
       "23132-87              0.0       0.0  \n",
       "42-MG-BA              0.0       0.0  \n",
       "\n",
       "[3 rows x 3432 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Cell-line gene matrix\\n{21*'='}\")\n",
    "assert len([col for col in cl_gene_mat.columns[1:] if '_gexpr' in col]) == \\\n",
    "    len([col for col in cl_gene_mat.columns[1:] if '_cnvg' in col]) == \\\n",
    "    len([col for col in cl_gene_mat.columns[1:] if '_cnvp' in col]) == \\\n",
    "    len([col for col in cl_gene_mat.columns[1:] if '_mut' in col])\n",
    "cl_gene_mat.set_index('CELL_LINE_NAME', inplace=True)    \n",
    "print(cl_gene_mat.shape)\n",
    "print(f\"unique cell-lines: {len(cl_gene_mat.index.unique())}\")\n",
    "cl_gene_mat.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drug SMILES fingerprint matrix\n",
      "==============================\n",
      "(152, 256)\n",
      "unique drugs: 152\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>246</th>\n",
       "      <th>247</th>\n",
       "      <th>248</th>\n",
       "      <th>249</th>\n",
       "      <th>250</th>\n",
       "      <th>251</th>\n",
       "      <th>252</th>\n",
       "      <th>253</th>\n",
       "      <th>254</th>\n",
       "      <th>255</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DRUG_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1073</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1910</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1913</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 256 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0    1    2    3    4    5    6    7    8    9    ...  246  247  248  \\\n",
       "DRUG_ID                                                    ...                  \n",
       "1073       0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "1910       1    1    0    0    0    0    0    0    0    0  ...    1    0    0   \n",
       "1913       0    1    1    0    1    0    0    0    0    0  ...    0    0    0   \n",
       "\n",
       "         249  250  251  252  253  254  255  \n",
       "DRUG_ID                                     \n",
       "1073       0    0    0    0    0    0    1  \n",
       "1910       0    0    1    0    0    0    1  \n",
       "1913       0    1    1    0    0    0    0  \n",
       "\n",
       "[3 rows x 256 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Drug SMILES fingerprint matrix\\n{30*'='}\")\n",
    "drug_mat.set_index('DRUG_ID', inplace=True)\n",
    "print(drug_mat.shape)\n",
    "print(f\"unique drugs: {len(drug_mat.index.unique())}\")\n",
    "drug_mat.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drug response matrix\n",
      "====================\n",
      "(91991, 5)\n",
      "unique cell-lines: 732\n",
      "unique drugs     : 152\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CELL_LINE_NAME</th>\n",
       "      <th>DRUG_ID</th>\n",
       "      <th>DRUG_NAME</th>\n",
       "      <th>DATASET</th>\n",
       "      <th>LN_IC50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3441054</th>\n",
       "      <td>22RV1</td>\n",
       "      <td>1003</td>\n",
       "      <td>Camptothecin</td>\n",
       "      <td>GDSC2</td>\n",
       "      <td>-3.142631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3459252</th>\n",
       "      <td>22RV1</td>\n",
       "      <td>1004</td>\n",
       "      <td>Vinblastine</td>\n",
       "      <td>GDSC2</td>\n",
       "      <td>-4.459259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3508920</th>\n",
       "      <td>22RV1</td>\n",
       "      <td>1006</td>\n",
       "      <td>Cytarabine</td>\n",
       "      <td>GDSC2</td>\n",
       "      <td>3.826935</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        CELL_LINE_NAME  DRUG_ID     DRUG_NAME DATASET   LN_IC50\n",
       "3441054          22RV1     1003  Camptothecin   GDSC2 -3.142631\n",
       "3459252          22RV1     1004   Vinblastine   GDSC2 -4.459259\n",
       "3508920          22RV1     1006    Cytarabine   GDSC2  3.826935"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Drug response matrix\\n{20*'='}\")\n",
    "print(drm.shape)\n",
    "print(f\"unique cell-lines: {len(drm.CELL_LINE_NAME.unique())}\")\n",
    "print(f\"unique drugs     : {len(drm.DRUG_ID.unique())}\")\n",
    "drm.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create `PyTorch` dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Dataset as PyGDataset\n",
    "\n",
    "class TabTabDataset(PyGDataset):\n",
    "    def __init__(self, cl_mat, drug_mat, drm):\n",
    "        super().__init__()\n",
    "        self.cl_mat = cl_mat\n",
    "        self.drug_mat = drug_mat\n",
    "\n",
    "        drm.reset_index(drop=True, inplace=True)\n",
    "        self.cls = drm['CELL_LINE_NAME']\n",
    "        self.drug_ids = drm['DRUG_ID']\n",
    "        self.drug_names = drm['DRUG_NAME']\n",
    "        self.ic50s = drm['LN_IC50']\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ic50s)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        \"\"\"\n",
    "        Returns a tuple of cell-line-gene features, drug smiles fingerprints \n",
    "        and the corresponding ln(IC50) values for a given index.\n",
    "\n",
    "        Args:\n",
    "            idx (`int`): Index to specify the row in the drug response matrix.  \n",
    "        Returns\n",
    "            `Tuple[np.ndarray, np.ndarray, np.float64]]`: Tuple of cell-line \n",
    "                gene feature values, drug SMILES fingerprints and the \n",
    "                corresponding ln(IC50) target values.\n",
    "        \"\"\"\n",
    "        return (self.cl_mat.loc[self.cls.iloc[idx]], \n",
    "                self.drug_mat.loc[self.drug_ids.iloc[idx]],\n",
    "                self.ic50s.iloc[idx])\n",
    "\n",
    "    def print_summary(self):\n",
    "        print(f\"TabTabDataset Summary\")\n",
    "        print(21*'=')\n",
    "        print(f\"# observations :\", len(self.ic50s))\n",
    "        print(f\"# cell-lines   :\", len(np.unique(self.cls)))\n",
    "        print(f\"# drugs        :\", len(np.unique(self.drug_names)))\n",
    "        print(f\"# genes        :\", len([col for col in self.cl_mat.columns[1:] if '_cnvg' in col]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TabTabDataset Summary\n",
      "=====================\n",
      "# observations : 91991\n",
      "# cell-lines   : 732\n",
      "# drugs        : 152\n",
      "# genes        : 858\n"
     ]
    }
   ],
   "source": [
    "tab_tab_dataset = TabTabDataset(cl_mat=cl_gene_mat, drug_mat=drug_mat, drm=drm)\n",
    "tab_tab_dataset.print_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self, batch_size, lr, train_ratio, val_ratio, num_epochs):\n",
    "        self.BATCH_SIZE = batch_size\n",
    "        self.LR = lr\n",
    "        self.TRAIN_RATIO = train_ratio\n",
    "        self.TEST_VAL_RATIO = 1-self.TRAIN_RATIO\n",
    "        self.VAL_RATIO = val_ratio\n",
    "        self.NUM_EPOCHS = num_epochs\n",
    "        self.RANDOM_SEED = 12345      \n",
    "\n",
    "args = Args(batch_size=1_000, \n",
    "            lr=0.0001, \n",
    "            train_ratio=0.8, \n",
    "            val_ratio=0.5, \n",
    "            num_epochs=300)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create `DataLoader` datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CELL_LINE_NAME    False\n",
      "DRUG_ID           False\n",
      "DRUG_NAME         False\n",
      "DATASET           False\n",
      "LN_IC50           False\n",
      "dtype: bool\n",
      "FBXL12_gexpr    False\n",
      "PIN1_gexpr      False\n",
      "PAK4_gexpr      False\n",
      "GNA15_gexpr     False\n",
      "ARPP19_gexpr    False\n",
      "                ...  \n",
      "MYL9_mut        False\n",
      "MLLT11_mut      False\n",
      "PFKL_mut        False\n",
      "FGFR4_mut       False\n",
      "SDHB_mut        False\n",
      "Length: 3432, dtype: bool\n",
      "0      False\n",
      "1      False\n",
      "2      False\n",
      "3      False\n",
      "4      False\n",
      "       ...  \n",
      "251    False\n",
      "252    False\n",
      "253    False\n",
      "254    False\n",
      "255    False\n",
      "Length: 256, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "print(drm.isna().any())\n",
    "print(cl_gene_mat.isna().any())\n",
    "print(drug_mat.isna().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FBXL12_gexpr    0\n",
       "PIN1_gexpr      0\n",
       "PAK4_gexpr      0\n",
       "GNA15_gexpr     0\n",
       "ARPP19_gexpr    0\n",
       "               ..\n",
       "PFKL_gexpr      0\n",
       "FGFR4_gexpr     0\n",
       "SDHB_gexpr      0\n",
       "FBXL12_cnvg     0\n",
       "PIN1_cnvg       0\n",
       "Length: 860, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl_gene_mat.isna().sum().head(860)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set.shape: (73592, 5)\n",
      "test_set.shape: (9199, 5)\n",
      "val_set.shape: (9200, 5)\n",
      "\n",
      "train_dataset\n",
      "TabTabDataset Summary\n",
      "=====================\n",
      "# observations : 73592\n",
      "# cell-lines   : 732\n",
      "# drugs        : 152\n",
      "# genes        : 858\n",
      "\n",
      "test_dataset\n",
      "TabTabDataset Summary\n",
      "=====================\n",
      "# observations : 9199\n",
      "# cell-lines   : 732\n",
      "# drugs        : 152\n",
      "# genes        : 858\n",
      "\n",
      "val_dataset\n",
      "TabTabDataset Summary\n",
      "=====================\n",
      "# observations : 9200\n",
      "# cell-lines   : 732\n",
      "# drugs        : 152\n",
      "# genes        : 858\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def _collate_tab_tab(samples):\n",
    "    cls, drugs, ic50s = map(list, zip(*samples))\n",
    "    cls = [torch.tensor(cl, dtype=torch.float64) for cl in cls]\n",
    "    drugs = [torch.tensor(drug, dtype=torch.float64) for drug in drugs]\n",
    "    # print(\"\\nCELL-LINES: \", cls[0])\n",
    "    # print(\"\\nDRUG:\", drugs[0])\n",
    "    # print(\"\\nIC50: \", ic50s[0])\n",
    "    \n",
    "    return torch.stack(cls, 0), torch.stack(drugs, 0), torch.tensor(ic50s)\n",
    "\n",
    "def create_datasets(drm, cl_mat, drug_mat):\n",
    "    train_set, test_val_set = train_test_split(drm, test_size=args.TEST_VAL_RATIO, random_state=args.RANDOM_SEED, stratify=drm['CELL_LINE_NAME'])\n",
    "    test_set, val_set = train_test_split(test_val_set, test_size=args.VAL_RATIO, random_state=args.RANDOM_SEED, stratify=test_val_set['CELL_LINE_NAME'])\n",
    "\n",
    "    print(\"train_set.shape:\", train_set.shape)\n",
    "    print(\"test_set.shape:\", test_set.shape)\n",
    "    print(\"val_set.shape:\", val_set.shape)\n",
    "\n",
    "    train_dataset = TabTabDataset(cl_mat=cl_mat, drug_mat=drug_mat, drm=train_set)\n",
    "    test_dataset = TabTabDataset(cl_mat=cl_mat, drug_mat=drug_mat, drm=test_set)\n",
    "    val_dataset = TabTabDataset(cl_mat=cl_mat, drug_mat=drug_mat, drm=val_set)\n",
    "\n",
    "    print(\"\\ntrain_dataset\"); train_dataset.print_summary()\n",
    "    print(\"\\ntest_dataset\"); test_dataset.print_summary()\n",
    "    print(\"\\nval_dataset\"); val_dataset.print_summary()\n",
    "\n",
    "    train_loader = DataLoader(dataset=train_dataset, batch_size=args.BATCH_SIZE, shuffle=True, collate_fn=_collate_tab_tab)\n",
    "    test_loader = DataLoader(dataset=test_dataset, batch_size=args.BATCH_SIZE, shuffle=True, collate_fn=_collate_tab_tab)\n",
    "    val_loader = DataLoader(dataset=val_dataset, batch_size=args.BATCH_SIZE, shuffle=True, collate_fn=_collate_tab_tab)\n",
    "\n",
    "    return train_loader, test_loader, val_loader\n",
    "\n",
    "train_loader, test_loader, val_loader = create_datasets(drm, cl_gene_mat, drug_mat)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of batches per dataset:\n",
      "  train : 74\n",
      "  test  : 10\n",
      "  val   : 10\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of batches per dataset:\")\n",
    "print(f\"  train : {len(train_loader)}\")\n",
    "print(f\"  test  : {len(test_loader)}\")\n",
    "print(f\"  val   : {len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(FBXL12_gexpr    7.023759\n",
       " PIN1_gexpr      6.067534\n",
       " PAK4_gexpr      4.318750\n",
       " GNA15_gexpr     3.261427\n",
       " ARPP19_gexpr    6.297582\n",
       "                   ...   \n",
       " MYL9_mut        0.000000\n",
       " MLLT11_mut      1.000000\n",
       " PFKL_mut        0.000000\n",
       " FGFR4_mut       1.000000\n",
       " SDHB_mut        0.000000\n",
       " Name: 22RV1, Length: 3432, dtype: float64,\n",
       " 0      1\n",
       " 1      0\n",
       " 2      0\n",
       " 3      0\n",
       " 4      0\n",
       "       ..\n",
       " 251    1\n",
       " 252    0\n",
       " 253    0\n",
       " 254    0\n",
       " 255    0\n",
       " Name: 1004, Length: 256, dtype: int64,\n",
       " -4.459259)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tab_tab_dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1:\n",
      "=======\n",
      "torch.Size([1000, 3432])\n",
      "torch.Size([1000, 256])\n",
      "torch.Size([1000])\n",
      "Step 2:\n",
      "=======\n",
      "torch.Size([1000, 3432])\n",
      "torch.Size([1000, 256])\n",
      "torch.Size([1000])\n",
      "Step 3:\n",
      "=======\n",
      "torch.Size([1000, 3432])\n",
      "torch.Size([1000, 256])\n",
      "torch.Size([1000])\n",
      "... step 10\n",
      "... step 20\n",
      "... step 30\n",
      "... step 40\n",
      "... step 50\n",
      "... step 60\n",
      "... step 70\n",
      "Step 74:\n",
      "=======\n",
      "torch.Size([592, 3432])\n",
      "torch.Size([592, 256])\n",
      "torch.Size([592])\n"
     ]
    }
   ],
   "source": [
    "for step, data in enumerate(train_loader):\n",
    "    if (step > 2) & (step < len(train_loader)-1):\n",
    "        if step % 10 == 0: \n",
    "            print(\"... step\", step) \n",
    "        continue\n",
    "    else:\n",
    "        cl_mat, drug_mat, ic50s = data\n",
    "        print(f'Step {step + 1}:')\n",
    "        print(f'=======')    \n",
    "        print(cl_mat.shape)\n",
    "        print(drug_mat.shape)\n",
    "        print(ic50s.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from time import sleep\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "\n",
    "class BuildModel:\n",
    "    def __init__(self, model, criterion, optimizer, num_epochs, \n",
    "        train_loader, test_loader, val_loader, device):\n",
    "        self.train_losses = []\n",
    "        self.test_losses = []\n",
    "        self.val_losses = []\n",
    "        self.train_loader = train_loader \n",
    "        self.test_loader = test_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.num_epochs = num_epochs\n",
    "        self.model = model \n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer \n",
    "        self.device = device\n",
    "\n",
    "    def train(self, loader): \n",
    "        train_epoch_losses, val_epoch_losses = [], []\n",
    "        all_batch_losses = [] # TODO: this is just for monitoring\n",
    "        n_batches = len(loader)\n",
    "        for epoch in range(self.num_epochs): \n",
    "            self.model.train()\n",
    "            # print(\"=====Epoch \", epoch, \" | Training...\")\n",
    "            batch_losses = []\n",
    "            for data in tqdm(loader, desc='Iter', position=0, leave=True):\n",
    "                sleep(0.01)\n",
    "                cl, dr, ic50 = data\n",
    "                cl, dr, ic50 = cl.to(self.device), dr.to(self.device), ic50.to(self.device)\n",
    "                # print(\"cl: \", cl.shape, cl); print(\"dr: \", dr.shape, dr); print(\"ic50: \", y.shape, y)\n",
    "\n",
    "                self.optimizer.zero_grad()                \n",
    "\n",
    "                preds = self.model(cl.float(), dr.float()).unsqueeze(1) # TODO: unsqueeze can be added to forward\n",
    "                # print(preds.shape)\n",
    "                # print(\"preds:\", preds)\n",
    "                loss = self.criterion(preds, ic50.view(-1,1).float())\n",
    "                batch_losses.append(loss)\n",
    "\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "            # print(batch_losses)\n",
    "            all_batch_losses.append(batch_losses) # TODO: this is just for monitoring\n",
    "            total_epoch_loss = sum(batch_losses)\n",
    "            train_epoch_losses.append(total_epoch_loss / n_batches)\n",
    "\n",
    "            mse, _, _, _, _ = self.validate(val_loader)\n",
    "            val_epoch_losses.append(mse)\n",
    "\n",
    "            if epoch % 25 == 0:\n",
    "                print(\"=====Epoch \", epoch)\n",
    "                print(f\"Train      | MSE: {train_epoch_losses[-1]:2.5f}\")\n",
    "                print(f\"Validation | MSE: {mse:2.5f}\")\n",
    "\n",
    "        return train_epoch_losses, val_epoch_losses\n",
    "\n",
    "    def validate(self, loader):\n",
    "        self.model.eval()\n",
    "        y_true, y_pred = [], []\n",
    "        total_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for data in tqdm(loader, desc='Iter', position=0, leave=True):\n",
    "                sleep(0.01)\n",
    "                cl, dr, ic50 = data\n",
    "\n",
    "                preds = self.model(cl.float(), dr.float()).unsqueeze(1)\n",
    "                ic50 = ic50.to(self.device)\n",
    "                total_loss += self.criterion(preds, ic50.view(-1,1).float())\n",
    "                # total_loss += F.mse_loss(preds, ic50.view(-1, 1).float(), reduction='sum')\n",
    "                y_true.append(ic50.view(-1, 1))\n",
    "                y_pred.append(preds)\n",
    "        \n",
    "        y_true = torch.cat(y_true, dim=0)\n",
    "        y_pred = torch.cat(y_pred, dim=0)\n",
    "        mse = total_loss / len(loader)\n",
    "        rmse = torch.sqrt(mse)\n",
    "        mae = mean_absolute_error(y_true.cpu(), y_pred.cpu())\n",
    "        r2 = r2_score(y_true.cpu(), y_pred.cpu())\n",
    "        pearson_corr_coef, _ = pearsonr(y_true.cpu().numpy().flatten(), \n",
    "                                        y_pred.cpu().numpy().flatten())\n",
    "\n",
    "        return mse, rmse, mae, r2, pearson_corr_coef\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cpu\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "\n",
    "# from TabTab import TabTabModel\n",
    "\n",
    "class TabTabModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TabTabModel, self).__init__()\n",
    "        self.cell_branch = nn.Sequential(\n",
    "            nn.Linear(3432, 516),\n",
    "            nn.BatchNorm1d(516),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.1),\n",
    "            nn.Linear(516, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.1),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU()         \n",
    "        )\n",
    "\n",
    "        self.drug_branch = nn.Sequential(\n",
    "            nn.Linear(256, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.1),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU()          \n",
    "        )\n",
    "\n",
    "        self.fcn = nn.Sequential(\n",
    "            nn.Linear(2*128, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(p=0.1),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(p=0.1),\n",
    "            nn.Linear(64, 1)\n",
    "            # nn.BatchNorm1d(1),\n",
    "            # nn.ReLU()\n",
    "        )     \n",
    "\n",
    "    def forward(self, cell, drug):\n",
    "        cell_emb = self.cell_branch(cell)  # Create cell gene vector embedding.\n",
    "        drug_emb = self.drug_branch(drug)  # Create compound vector embedding.\n",
    "        # print(\"cell_emb: \", cell_emb.shape)\n",
    "        # print(\"drug_emb: \", drug_emb.shape)\n",
    "\n",
    "        concat = torch.cat([cell_emb, drug_emb], 1)\n",
    "        # print(concat.shape)\n",
    "        # print(concat)\n",
    "\n",
    "        # x_dim_batch, y_dim_branch, z_dim_features = concat.shape[0], concat.shape[1], concat.shape[2]\n",
    "        # concat = torch.reshape(concat, (x_dim_batch, y_dim_branch*z_dim_features))\n",
    "        \n",
    "        y_pred = self.fcn(concat)\n",
    "        y_pred = y_pred.reshape(y_pred.shape[0])\n",
    "        return y_pred\n",
    "\n",
    "torch.manual_seed(args.RANDOM_SEED)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"device:\", device)\n",
    "\n",
    "model = TabTabModel().to(device)\n",
    "loss_func = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=args.LR)\n",
    "\n",
    "build_model = BuildModel(model, loss_func, optimizer, args.NUM_EPOCHS, \n",
    "                         train_loader, test_loader, val_loader,\n",
    "                         device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter: 100%|██████████| 74/74 [01:37<00:00,  1.32s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:23<00:00,  2.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====Epoch  0\n",
      "Train      | MSE: 10.92296\n",
      "Validation | MSE: 7.30963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter: 100%|██████████| 74/74 [17:23<00:00, 14.10s/it]  \n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.08s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:28<00:00,  1.20s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:28<00:00,  1.20s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.03s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:32<00:00,  1.26s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:11<00:00,  1.20s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:30<00:00,  1.23s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.00s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:28<00:00,  1.20s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:29<00:00,  1.21s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:29<00:00,  1.21s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:28<00:00,  1.20s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:29<00:00,  1.21s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:29<00:00,  1.21s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.00it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:32<00:00,  1.25s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.04it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:28<00:00,  1.19s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:28<00:00,  1.20s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:28<00:00,  1.19s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.00it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:28<00:00,  1.20s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.00s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:28<00:00,  1.20s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:28<00:00,  1.20s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.00s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:29<00:00,  1.20s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.00s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:28<00:00,  1.20s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:28<00:00,  1.20s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:28<00:00,  1.20s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:28<00:00,  1.20s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:29<00:00,  1.21s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:29<00:00,  1.21s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====Epoch  25\n",
      "Train      | MSE: 1.31992\n",
      "Validation | MSE: 1.23547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter: 100%|██████████| 74/74 [01:28<00:00,  1.20s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.00s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:29<00:00,  1.20s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:29<00:00,  1.21s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.06s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:30<00:00,  1.22s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:28<00:00,  1.19s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.04s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:29<00:00,  1.20s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:29<00:00,  1.21s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.00s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:29<00:00,  1.20s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.02s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:29<00:00,  1.20s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:29<00:00,  1.21s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:28<00:00,  1.20s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.04s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:28<00:00,  1.20s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:28<00:00,  1.20s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.00s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:30<00:00,  1.22s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.02it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:25<00:00,  1.15s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.03it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:25<00:00,  1.16s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.02it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:25<00:00,  1.16s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.03it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:25<00:00,  1.16s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:29<00:00,  1.21s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.03it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:25<00:00,  1.15s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.03it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:29<00:00,  1.21s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.03s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:29<00:00,  1.21s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.07s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:28<00:00,  1.20s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:28<00:00,  1.20s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:29<00:00,  1.20s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====Epoch  50\n",
      "Train      | MSE: 1.08509\n",
      "Validation | MSE: 1.00775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter: 100%|██████████| 74/74 [01:29<00:00,  1.21s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:29<00:00,  1.21s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:28<00:00,  1.20s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.03s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:29<00:00,  1.21s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:28<00:00,  1.20s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:28<00:00,  1.20s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.02s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:28<00:00,  1.19s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.03it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:25<00:00,  1.15s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.03it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:25<00:00,  1.15s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.02it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:29<00:00,  1.20s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.03it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:28<00:00,  1.19s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:29<00:00,  1.20s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:29<00:00,  1.21s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.00s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:28<00:00,  1.20s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:29<00:00,  1.21s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.02s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:30<00:00,  1.22s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:28<00:00,  1.20s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:29<00:00,  1.21s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:29<00:00,  1.21s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.03s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:29<00:00,  1.20s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.02s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:29<00:00,  1.21s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:29<00:00,  1.21s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.04s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:29<00:00,  1.21s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:29<00:00,  1.20s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:28<00:00,  1.20s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====Epoch  75\n",
      "Train      | MSE: 0.98334\n",
      "Validation | MSE: 0.96934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter: 100%|██████████| 74/74 [01:29<00:00,  1.21s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:28<00:00,  1.20s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.00s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:28<00:00,  1.20s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:29<00:00,  1.21s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.00s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:28<00:00,  1.20s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.00it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.19s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.00it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:28<00:00,  1.19s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:28<00:00,  1.19s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.06it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:23<00:00,  1.13s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.07it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:22<00:00,  1.12s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.07it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:22<00:00,  1.12s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.02it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.03s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:28<00:00,  1.19s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:11<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:28<00:00,  1.20s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.03s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:25<00:00,  1.16s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.07it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:25<00:00,  1.15s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.04it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:24<00:00,  1.15s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.06it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:25<00:00,  1.15s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.02it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.06it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:30<00:00,  1.23s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:34<00:00,  1.27s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.02it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:11<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:24<00:00,  1.14s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====Epoch  100\n",
      "Train      | MSE: 0.92735\n",
      "Validation | MSE: 0.91169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter: 100%|██████████| 74/74 [01:29<00:00,  1.21s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:30<00:00,  1.22s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.00s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.19s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.00it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:28<00:00,  1.19s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.00it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.19s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.00it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:28<00:00,  1.20s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:11<00:00,  1.10s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:31<00:00,  1.24s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.00s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.19s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.00it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.19s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.03s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:28<00:00,  1.19s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.00it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:31<00:00,  1.24s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.06s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:37<00:00,  1.32s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.03s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:28<00:00,  1.19s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.04it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:24<00:00,  1.14s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.05it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:23<00:00,  1.13s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.06it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:23<00:00,  1.13s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.06it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.00s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:28<00:00,  1.20s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:28<00:00,  1.20s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.00it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:28<00:00,  1.19s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.16s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.07it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.00it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====Epoch  125\n",
      "Train      | MSE: 0.87510\n",
      "Validation | MSE: 0.92339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.05it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:24<00:00,  1.15s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.00s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:24<00:00,  1.14s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.06it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:28<00:00,  1.19s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:23<00:00,  1.13s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.00s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:28<00:00,  1.19s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:24<00:00,  1.15s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.07it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:25<00:00,  1.15s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.07it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.00s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:25<00:00,  1.16s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.06it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:25<00:00,  1.16s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.02s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:25<00:00,  1.15s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.07it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.00s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.00s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.06it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:24<00:00,  1.14s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.00s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.19s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.06it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:25<00:00,  1.15s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====Epoch  150\n",
      "Train      | MSE: 0.83066\n",
      "Validation | MSE: 0.88861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.19s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.00it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:25<00:00,  1.16s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.07it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:25<00:00,  1.16s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.00it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:24<00:00,  1.14s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.04it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:28<00:00,  1.19s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.00it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:25<00:00,  1.16s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.07it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.00it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.07it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:24<00:00,  1.14s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.00s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.19s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.05it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:23<00:00,  1.12s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.06it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:23<00:00,  1.13s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.00it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.19s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.03it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.00it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:25<00:00,  1.16s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.04it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:25<00:00,  1.16s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.02s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.00it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:24<00:00,  1.14s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====Epoch  175\n",
      "Train      | MSE: 0.79286\n",
      "Validation | MSE: 0.85819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.00it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.06it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:23<00:00,  1.13s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.00s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.19s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:24<00:00,  1.15s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.06it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:24<00:00,  1.14s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.07it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.00it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.16s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.05it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:25<00:00,  1.15s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.19s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:23<00:00,  1.13s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.02it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.16s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:24<00:00,  1.14s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.03it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:25<00:00,  1.16s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.04s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.00it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.00s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:25<00:00,  1.15s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====Epoch  200\n",
      "Train      | MSE: 0.76515\n",
      "Validation | MSE: 0.86072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter: 100%|██████████| 74/74 [01:25<00:00,  1.15s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.00s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.03it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:25<00:00,  1.16s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.07it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:24<00:00,  1.14s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.02it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.19s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.00s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.02it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.06it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:24<00:00,  1.14s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.00s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:23<00:00,  1.13s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.05it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:22<00:00,  1.12s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.05it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.00s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:25<00:00,  1.16s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.06it/s]\n",
      "Iter: 100%|██████████| 74/74 [02:53<00:00,  2.34s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.19s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.02s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:30<00:00,  1.22s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.07s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:30<00:00,  1.23s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.03s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:29<00:00,  1.21s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.06it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.16s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====Epoch  225\n",
      "Train      | MSE: 0.73852\n",
      "Validation | MSE: 0.82977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.03it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:22<00:00,  1.12s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.05it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:22<00:00,  1.12s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.07it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:22<00:00,  1.12s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.06it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:22<00:00,  1.12s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.05it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:22<00:00,  1.12s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.06it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:22<00:00,  1.12s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.05it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:23<00:00,  1.13s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.06it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:23<00:00,  1.13s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.06it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:22<00:00,  1.12s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.05it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.05s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.16s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.05it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:23<00:00,  1.13s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.04s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:30<00:00,  1.22s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.00it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:25<00:00,  1.15s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.05it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:22<00:00,  1.12s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.06it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:22<00:00,  1.12s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.06it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:22<00:00,  1.12s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.07it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:22<00:00,  1.11s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.06it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:22<00:00,  1.12s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.00it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:28<00:00,  1.19s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:31<00:00,  1.24s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.07s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.02it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.06it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:22<00:00,  1.12s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====Epoch  250\n",
      "Train      | MSE: 0.71375\n",
      "Validation | MSE: 0.83597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter: 100%|██████████| 74/74 [01:22<00:00,  1.11s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.06it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:23<00:00,  1.13s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.07it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:22<00:00,  1.12s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.05it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:22<00:00,  1.12s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.08it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:36<00:00,  1.30s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.03it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:31<00:00,  1.23s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.05it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:23<00:00,  1.13s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.06it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:24<00:00,  1.14s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.04it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:23<00:00,  1.13s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.04it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:23<00:00,  1.13s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.06it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:23<00:00,  1.13s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.05it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:24<00:00,  1.14s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.05it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:23<00:00,  1.13s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.05it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:24<00:00,  1.14s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.05s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.03s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.02it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.02it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.02it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.05it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:25<00:00,  1.16s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.02it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.03it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====Epoch  275\n",
      "Train      | MSE: 0.69882\n",
      "Validation | MSE: 0.81370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.02it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.02it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.02it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.00s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.02it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.02it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "Iter: 100%|██████████| 74/74 [01:27<00:00,  1.18s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:26<00:00,  1.17s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Iter: 100%|██████████| 74/74 [01:18<00:00,  1.06s/it]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.02it/s]\n",
      "Iter: 100%|██████████| 10/10 [00:09<00:00,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 mse      rmse       mae        r2         r\n",
      "----------  --------  --------  --------  --------  --------\n",
      "train       0.450149  0.670932  0.51781   0.938216  0.968843\n",
      "validation  0.811576  0.900875  0.662914  0.889404  0.943088\n",
      "test        0.83026   0.911186  0.669223  0.886715  0.941691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_losses, val_losses = build_model.train(build_model.train_loader)\n",
    "\n",
    "tr_mse, tr_rmse, tr_mae, tr_r2, tr_r = build_model.validate(build_model.train_loader)\n",
    "val_mse, val_rmse, val_mae, val_r2, val_r = build_model.validate(build_model.val_loader)\n",
    "te_mse, te_rmse, te_mae, te_r2, te_r = build_model.validate(build_model.test_loader)\n",
    "\n",
    "results = tabulate(\n",
    "    [\n",
    "        ['mse', 'rmse', 'mae', 'r2', 'r'],\n",
    "        ['train', tr_mse, tr_rmse, tr_mae, tr_r2, tr_r],\n",
    "        ['validation', val_mse, val_rmse, val_mae, val_r2, val_r],\n",
    "        ['test', te_mse, te_rmse, te_mae, te_r2, te_r]\n",
    "    ], headers='firstrow')\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "n_epochs = 100\n",
    "    mse     rmse       mae        r2         r\n",
    "-------  -------  --------  --------  --------\n",
    "1.34979  1.1618   0.580942  0.814719  0.92687\n",
    "2.09012  1.44572  0.981567  0.709278  0.858571\n",
    "2.14415  1.46429  0.983369  0.709229  0.857674\n",
    "\n",
    "n_epochs = 300\n",
    "                 mse      rmse       mae        r2         r\n",
    "----------  --------  --------  --------  --------  --------\n",
    "train       0.450149  0.670932  0.51781   0.938216  0.968843\n",
    "validation  0.811576  0.900875  0.662914  0.889404  0.943088\n",
    "test        0.83026   0.911186  0.669223  0.886715  0.941691\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 mse      rmse       mae        r2         r\n",
      "----------  --------  --------  --------  --------  --------\n",
      "train       0.450149  0.670932  0.51781   0.938216  0.968843\n",
      "validation  0.811576  0.900875  0.662914  0.889404  0.943088\n",
      "test        0.83026   0.911186  0.669223  0.886715  0.941691\n"
     ]
    }
   ],
   "source": [
    "results = tabulate(\n",
    "    [\n",
    "        ['mse', 'rmse', 'mae', 'r2', 'r'],\n",
    "        ['train', tr_mse, tr_rmse, tr_mae, tr_r2, tr_r],\n",
    "        ['validation', val_mse, val_rmse, val_mae, val_r2, val_r],\n",
    "        ['test', te_mse, te_rmse, te_mae, te_r2, te_r]\n",
    "    ], headers='firstrow')\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA on Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([loss.item() for loss in train_losses], c='C0', label='train');\n",
    "plt.plot([loss.item() for loss in val_losses], c='C1', label='validation');\n",
    "plt.legend();\n",
    "plt.ticklabel_format(style='plain');\n",
    "plt.xlim(0, args.NUM_EPOCHS, 1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(build_model.model.state_dict(), '../../datasets/models/TabTab_v1.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 95264\n",
      "-rw-r--r--  1 cwoest  staff   8.1M Sep 28 13:52 Model2CnvGistic__cnv_gistic.pkl\n",
      "-rw-r--r--  1 cwoest  staff   8.1M Sep 28 14:37 Model2CnvGistic__cnv_picnic.pkl\n",
      "-rw-r--r--  1 cwoest  staff   7.8M Nov 11 19:03 TabTab_v1.pkl\n",
      "-rw-r--r--  1 cwoest  staff   7.8M Nov 11 19:04 TabTab_v1.pt\n",
      "-rw-r--r--  1 cwoest  staff   8.1M Sep 28 13:12 model2.pkl\n",
      "-rw-r--r--  1 cwoest  staff   1.3M Aug 24 16:00 simpleNN\n",
      "-rw-r--r--  1 cwoest  staff   1.3M Aug 24 15:58 simpleNN.pkl\n",
      "-rw-r--r--  1 cwoest  staff   4.0M Aug 24 16:03 simpleNN_extensive.pkl\n"
     ]
    }
   ],
   "source": [
    "ls -lh ../../datasets/models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TabTabModel(\n",
       "  (cell_branch): Sequential(\n",
       "    (0): Linear(in_features=3432, out_features=516, bias=True)\n",
       "    (1): BatchNorm1d(516, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.1, inplace=False)\n",
       "    (4): Linear(in_features=516, out_features=256, bias=True)\n",
       "    (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU()\n",
       "    (7): Dropout(p=0.1, inplace=False)\n",
       "    (8): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (9): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): ReLU()\n",
       "  )\n",
       "  (drug_branch): Sequential(\n",
       "    (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.1, inplace=False)\n",
       "    (4): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (5): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU()\n",
       "  )\n",
       "  (fcn): Sequential(\n",
       "    (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ELU(alpha=1.0)\n",
       "    (3): Dropout(p=0.1, inplace=False)\n",
       "    (4): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (5): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ELU(alpha=1.0)\n",
       "    (7): Dropout(p=0.1, inplace=False)\n",
       "    (8): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model = TabTabModel()\n",
    "loaded_model.load_state_dict(torch.load('../../datasets/models/TabTab_v1.pt'))\n",
    "loaded_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.2950, grad_fn=<AddBackward0>)\n",
      "tensor(10.2950, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[tensor(0.9803, grad_fn=<MseLossBackward0>),\n",
       " tensor(2.1797, grad_fn=<MseLossBackward0>),\n",
       " tensor(3.0829, grad_fn=<MseLossBackward0>),\n",
       " tensor(2.1547, grad_fn=<MseLossBackward0>),\n",
       " tensor(1.8975, grad_fn=<MseLossBackward0>)]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outs = []\n",
    "os = 0\n",
    "for i in range(5):\n",
    "\n",
    "    loss = nn.MSELoss()\n",
    "    input = torch.randn(3, 5, requires_grad=True)\n",
    "    target = torch.randn(3, 5)\n",
    "    output = loss(input, target)\n",
    "    outs.append(output)\n",
    "    os += output\n",
    "    output.backward()\n",
    "print(sum(outs))\n",
    "print(os)\n",
    "outs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(13.1052, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c78b81650a0bd32063743affb6953ff71b1a0dba806fbca9e2db842718495748"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('master-thesis-log')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
